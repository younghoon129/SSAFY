# RAG 구조와 생성형 AI
- 생성형 AI
- RAG
- LangChain

# 생성형 AI
- 과거 AI, 좁은 AI
    - 각각의 작업마다 별도의 모델 필요
    53퍼
- 파운데이션과 언어 모델의 계층
    - 파운데이션 모델
        - 대규모 데이터셋에 기반해 범용적인 작업(텍스트, 이미지 등)을 수행할 수 있는 AI모델
    - LLM(Large Language Model)
        - 대규모 파라미터와 방대한 텍스트 데이터로 학습된 대형 언어 모델
    - SLM(Small Language Model)
        - 파라미터 수와 모델 크기를 줄인 경량화 버전의 언어 모델
- 언어모델의 한계
    - 세상은 언어로만 표현하기 어렵다
    - 정의는 이해가 되지만, 와닿지는 않는 내용
- 멀티모달의 등장
    - 텍스트 기반 언어모델의 한계를 보완해줄 새로운 기술
- 추론모델의 등장
    - 기억 기반(사전학습) 언어모델의 한계를 보완해줄 기술
    - 벤치마크 점수로 확인하는 추론모델의 장점

## RAG
- LLM 한계 극복
    - Prompt Engineering
        - 특정 작업에 대해 모델이 더 잘 반응하도록 입력 텍스트(프롬프트)를 최적화하는 방식

    - RAG(Retrieval-Augmented Geeration)
        - 입력 프롬프트와 검색 기반의 정보를 결합(증강)하여, 증강된 정보를 기반으로 답변을 생성하도록 하는 방식
        - 최신정보, 도메인지식 외부에서 가져옴
        - 정보 검색, 응답 생성을 결합한 모델
        - 사용자의 질문이 주어지면, Retriever는 관련된 정보나 문서를 데이터베이스에서 검색
        - 검색된 정보로 질문에 대한 답변 생성
        - 보다 풍부하고 정확한 정보를 제공 가능
        - Retrieval(검색)
            - 외부 데이터 및 소스를 검색하여 정보 획득
            - 필요한 정보를 검색하는 작업
            - 데이터베이스, 인터넷, 또는 다른 정보 저장소에서 관련 정보를 찾아내는 과정
            - 사용자의 쿼리에 가장 잘 맞는 데이터를 식별하고 추출하는 기술과 알고리즘
            - 웹 검색 엔진, 디지털 도서관, 온라인 데이터베잇, 정보 검색 시스템 등 다양한 분야에서 중요한 역할 수행
        - Augmented(증강)
            - 사용자의 질문을 보강하여 보다 정확한 문맥 제공
        - Generation(생성)
            - 향상된 정보를 기반으로 더 좋은 답변 생성
        - 답변할 때 확실한 출처를 기반으로 생성하게 됨
        - 역색인(Inverted Index)
            - 색인: 1 -> 1페이지 호출, 100 -> 100페이지 호출(데이터를 직접 위치에 연결)
            - 각 데이터에 빠르게 접근할 수 있도록 도움
            - 역색인: "학교" -> 3, 49, 100 페이지
            - 각 단어로 색인 정보를 연결 시켜 놓음으로 단어 기반 검색이 가능케 함
        - TF-IDF
            - 단어가 많이 나오면 점점 점수가 커짐(특정 문서에서)
            - 무조건 관련있다고는 장담 못함
            - TF-IDF(t, d, D) = TF(t, d) * IDF(t, D) t =단어, d = 문서, D = 전체문서
        - BM25
            - TF-IDF의 정보검색에서의 단점을 보완
            - 단어 빈도 고정, 일정 횟수 이상 넘어갈 경우 점수 증가 안함
            - 문서 길이 보정 -> 문서 길어서 단어가 많이 나오는 경우도 있을테니(점수 과도하게 높아질 가능성) 문서 평균 길이에 맞게 보정
            - Q: 사용자가 입력한 쿼리
            - D: 대조해보려는 문서
            - 대부분의 텍스트 기반 검색을 진행할 때 가장 자주 쓰이는 방식
        - 유사도 알고리즘
        - 벡터 임베딩을 통한 문서 검색
            - 검색에 더 좋은 벡터는 없을까?
        - BERT의 임베딩과 BM25의 성능 비교
            - BM25는 문서의 벡터 크기가 크지만, BERT에서의 문서 벡터는 768차원(논문 기준)
            - 단어 기반이 아닌 문맥 기반의 벡터가 retrieve시 성능이 더 좋은 경우가 많음

        - Sparse embedding(키워드 기반)
            - 대부분의 값이 0, 몇몇 위치만 값이 있는 벡터로 표현
            - 문장에 나오는 단어의 빈도를 기인준으로 벡터를 만듦
            - Tf-Idf, BM25 등
            - 겹치는 단어가 있으면 유사도가 높게 나오지만 단어 간의 의미적인 관계를 포착하지 못함
        - Dense Embedding(의미 기반)
            - 의미를 나타내는 실수 값들로 이루어진 벡터로 표현
            - BERT와 같은 Pretrained Language Model이 주로 사용 됨

        - 장점
            - 환각 현상 감소
            - 도메인 적응성 개선
            - Open domain QA 성능 향상
            - 참고한 Knowledge base가 적절한지 판단 가능
            - 정보 검색에 강함

    - Fine-Tuning
        - 사전 훈련된 모델을 특정 작업이나 데이터셋에 맞게 추가적으로 조정하는 방식


## LangChain
- LLM의 기능을 나만의 코드로 가져와서 이를 자유자재로 사용할 수 있게 해주는 강력한 '프레임워크'
- LLM으로 하는 모든 것을 LangChain을 통해서 할 수 있음을 의미
    - 프롬프트 엔지니어링
    - RAG(Retrieval Augmented Generation)
    - Agent
    - 외부 LLM API 사용 및 Local LLM 구동
    - Moderation
- LangChain을 통해서 다양한 외부 및 내부 라이브러리 통합을 쉽게 할 수 있음
- LLM과 여러 다른 소스들을 Chaining해서 복잡한 애플리케이션도 쉽게 구현
- 구성
    - LLM: 초거대 언어모델로, 생성 모델의 엔진과 같은 역할을 하는 핵심 구성 요소
    - Prompts: 초거대 언어모델에게 지시하는 명령문
    - Index: LLM이 문서를 쉽게 탐색할 수 있도록 구조화 하는 모듈
    - Chain: LLM 사슬을 형성하여 연속적인 LLM 호출이 가능하도록 하는 핵심 구성 요소
    - Agents: LLM이 기존 Prompt Template으로 수행할 수 없는 작업을 가능케 하는 모듈
- LLM 추상화(Abstraction) 제공
    - Language Model + Chain = LangChain
    - 추상화(Abstraction)란 사용자에게 불필요한 세부 사항을 숨겨 복잡성을 처리하는 것
    - 사용자는 숨겨진 복잡성을 모두 이해하거나 생각하지 않고 제공된 추상화에서 나만의 로직 구현 가능
    - 언어 모델(Language Model)을 연결(Chain)하여 애플리케이션 구축 가능
    - 모든 LLM 모델을 자세히 공부하지 않고도 간단히 사용 가능
- Prompts
    - Context와 Query를 수동으로 작성할 필요 없이 프롬프트의 구성을 구조화 함
- Chain
    - 체인을 연결하여 응답 처리를 연속적으로 실행 할 수 있도록 연결하는 기능
    - Sequential Chain(순차적으로 실행)
    - Router Chain(조건에 따라 다른 실행)
- Index
    - 자체 학습 데이터 셋에 포함되어 있지 않은 특정 외부 데이터 소스 총칭
    - Document Loader
        - 파일 저장 서비스와 같은 소스에서 데이터 소스를 가져옴
    - Vector DB
        - 데이터 포인터를 벡터 임베딩으로 변환하여 표현
        - 효율적인 검색 지원
    - Text Splitters
        - 의미 있는 작은 덩어리로 분할
        - 깔끔한 요약 정리 가능
- Agents
    - LLM과 다른 데이터 소스나 도구 두 가지 이상 조합하여 사용 가능
    - 선택한 LLM을 추론 엔진으로 사용하여 어떤 작업을 수행할 지 결정
- Chat Model
    - LLM은 다양한 언어 작업을 수행할 수 있는 범용 대규모 언어 모델이라면,
    - Chat Model은 대화 상호작용 및 대화에 최적화된 LLM의 특화된 버전
- LCEL(LangChain Expression Language)
    - 여러 체인을 연결하여 복잡한 워크플로우를 제어하거나 여러 논리적 흐름 생성 가능
    - '|'(연산자) : 서로 다른 구성 요소를 연결하고 한 구성 요소의 출력을 다음 구성 요소의 입력으로 전달
- LangChain으로 가능한 것들
    - 데이터 분석하기 - Excel
    - 웹에서 정보 수집하기 - URL
    - RAG를 활용한 문서 QA 챗봇
        - PDF 챗봇 구축 예시
            - 문서 업로드(PyPDFLoader를 활용한 문서 가져오기)
            - 문서 분할(PDF 문서를 여러 문서로 분할)
            - 문서 임베딩(LLM이 이해할 수 있도록 문서 수치화)
            - 임베딩 검색(질문과 연관성이 높은 문서 추출)
            - 답변 생성
- LangChain 챗봇 아키텍쳐
    - 비정형 데이터(pdf, txt, docs, ...)를 QA Chain으로 바꾸는 형태
- LangChain의 Retrieval
    - Retrieval은 RAG의 대부분의 구성 요소를 아우르며, 구성 요소 하나하나가 RAG의 품질의 좌우

## AI Agent
- AI Agent의 정의
    - 사용자의 목표를 달성하기 위해 스스로 문제를 분석하고, 해결 가능한 작은 작업 단위로 분해(Planning)한 뒤, 필요시 외부 툴이나 API를 활용하여 작업을 수행하며, 결과를 반복적으로 검토(Self-Reflection)하고 개선하는 시스템
    - LLM과 다른 데이터 소스나 도구 두 가지 이상 조합하여 사용 가능 선택한 LLM을 추론 엔진으로 사용하여 어떤 작업을 수행할 지 결정
    - ChatGPT는 AI Agent의 하위 개념 또는 구성 요소로 볼 수 있으며, 단순히 텍스트를 생성하는 언어모델
    - AI Agent는 ChatGPT 같은 LLM을 코어 엔진으로 활용하되, 추가적으로 툴 사용, 계획, 자율적 실행 기능이 결합된 시스템
- Tool
    - AI Agent가 활용할 수 있는 기능적 요소
    - AI가 혼자 해결하기 어려운 작업을 도와주는 보조 도구
    - 특정 작업을 위해 외부 기능이나 전문가를 불러오는 개념
    - 예: PDF 읽기, 웹 검색, 코드 실행 등
    - 역할 기반 설정 + 배경 지식 제공 + 실질적인 작업 처리 능력을 갖춘 자동화 에이전트 구성 가능
