# 데이터 EDA_TIL

- 데이터 시각화
- 모델 학습
- 성능 평가
- 성능 검증
- 비지도 학습
  - 군집화
  - 차원 축소

## 데이터 EDA(탐색적 데이터 분석)
- 데이터를 분석하기 전 여러 각도에서 관찰하고 이해하는 과정
- 중요성
  - 분석의 방향성 제시
    - 데이터의 특징을 파악하여 어떤 분석 기법을 적용하고, 어떤 모델을 구축할 지 결정하는 데 도움을 줌
  - 모델의 성능 향상
    - 데이터의 문제점을 미리 파악 후 해결함으로써 모델의 정확성과 안정성 높임
  - 새로운 인사이트 발견
    - 예상치 못한 데이터의 패턴, 관계를 발견하여 새로운 인사이트로 활용
- 진행순서(아래 과정은 단 방향이 아닌, 각 단계를 오가며 반복진행)
  1. 데이터 불러오고, 기본 정보 확인(타입, 결측치, 통계량 등)
  2. 데이터 정제 및 전처리
     - 결측치, 이상치, 중복값을 식별하고 처리하고, 올바르지 않은 데이터 타입 수정
     - 분석에 사용되지 않을 변수(열) 제거
  3. 개별 변수 분석
     - 변수의 분포와 특징을 이해
  4. 변수 간 관계 분석
     - 변수들 사이의 관계, 패턴, 상관관계를 파악
  5. 분석 결과 정리

## 데이터 시각화
- 그래프를 보는 것이 데이터 패턴을 훨씬 직관적으로 파악 가능
- Matplotlib, Seaborn을 활용
  - Matplotlib
    - C언어 기반
  - Seaborn
    - Matplotlib(C) 기반으로 한 Python
- 단변수 분석
  - 히스토그램(Histogram)
    - 특정 수치형 변수 **하나의 데이터 분포**를 파악하기 위해 사용
    - 데이터의 전체 범위를 여러 개의 동일한 구간(bin)으로 나눈 뒤, 각 구간에 속하는 데이터의 개수를 막대 그래프로 표현
    - 장점
      - 직관적으로 분포 파악
      - 이상치 탐지 수월
    - 단점
      - 구간(bin) 설정에 민감
    - 그래프의 봉우리가 1개 이상일 경우, 이는 1개 이상의 서로 다른 하위 그룹이 데이터에 섞여있다는 의미
  - 박스 플롯(Bot Plot) **이거 사분위 이용해서 이상치 뽑는 문제? 나올 수 있음(실습_2 - 데이터EDA)**
    - 수치형 데이터의 분포와 이상치를 한눈에 파악하기 위해 사용되는 그래프
    - 데이터의 사분위수(25%, 50%, 75%)를 이용, 전체 데이터가 어떻게 퍼져있는지 간결하게 요약
    - **이상치**를 찾는 데 매우 유용
    - 데이터 개수 파악 어려움, 데이터의 구체적인 분포 형태 파악 어려움
  - 산점도(Scatter Plot)
    - 두 개의 수치형 변수 사이의 관계를 파악하기 위해 점을 찍어 만든느 그래프
  - 히트맵(Heatmap)
    - 여러 숫자형 변수들 간의 크기를 색상으로 변환하여 보여주는 것
    - 주로 상관관계 분석에 많이 사용 됨
    - 장점
      - 직관적, 다변량 관계를 파악
  - 페어 플롯(Pair Plot)
    - 대각선(분포도)
    - 대각선 외(산점도)

## 모델 학습
- 주어진 데이터에만 과하게 최적화되어 훈련(기존 데이터)에서는 
- 과적합
  - 훈련 데이터에만 익숙해져, 데이터의 중요한 패턴을 넘어 사소한 잡음까지 전부 외워버리는 현상
  - 일반화 못하고, 훈련 데이터에 따라 예측이 크게 달라짐
- 과소적합
  - 모델이 너무 단순해서 훈련 데이터의 핵심적인 패턴조차 제대로 학습하지 못한 상태
- 데이터 분리
  - 주어진 데이터를 훈련 데이터와 테스트 데이터로 분리
  - 훈련 데이터: 모델을 학습시키는 용도로 활용
  - 테스트 데이터: 모델이 얼마나 새로운 데이터를 잘 예측하는지 **일반화 성능을 최종 평가**하는 용도
  - 일반적으로 7:3, 8:2(훈련:테스트)
- 스케일링 - 표준화 - 코드
- **테스트 데이터의 표준화는 훈련 데이터의 평균, 표준편차를 이용해야됨 이 부분 중요**


## 성능 평가
- 선형 회귀 모델은 MSE(평균 제곱 오차)를 활용해서 모델을 평가
- 분류 모델은?
  - 모델의 예측 값과 실제 정답을 비교, 모델이 얼마나 정답을 잘 맞혔는지 **객관적인 숫자**로 확인하는 과정
  - 평가 지표 **이거 문제 무조건 나옴**
    - 정확도
      - 맞은 예측 개수 / 전체 예측 개수
      - 가장 이해하기 쉽고, 직관적인 성능 평가 지표
      - 정확도가 아무리 높아도 안심 X
      - 불균형 데이터에서 정확도 99%이어도 1%는 틀렸기 때문에, 이런 모델은 쓸모없는 모델
  - 혼동 행렬(Confusion Matrix)
    - 분류 모델의 성능을 평가할 때 사용하는 가장 기본적, 강력한 도구
    - 어떤 실수를 어떻게 저질렀는지를 한눈에 보여주는 상세한 지표
    - Positive(찾으려는 대상(암, 스팸))
    - Negative(그 외의 대상(정상))
    - 작동원리 ((F,T - 맞음,틀림), (P,N - 모델이 내린 판단))
      - True Positive(TP)
        - 실제 Positive인 것을 모델이 Positive로 정확히 예측한 것
        - 정답
      - True Negative(TN)
        - 실제 Negative인 것을 모델이 Negative로 정확히 예측한 것
        - 정답
      - False Positive(FP)
        - 실제 Negative인 것을 모델이 Positive로 잘못 예측한 것
        - 모델의 섣부른 판단
      - False Negative(FN)**4가지 지표중 가장 중요**
        - 실제 Positive인 것을 모델이 Negative로 잘못 예측한 것
        - 모델이 놓침
    - 정밀도
      - TP의 비율
      - 모델의 예측이 얼마나 정교한지를 나타냄
      - TP / (TP+)
    - 재현율
      - 모델이 찾아야 할 것을 얼마나 빠짐없이 잘 찾아냈는지 나타냄
    - 조화 평균(F1-Score)
      - 정밀도와 재현율을 모두 고려하고, 균형 잡힌 성능을 나타낼 때 사용
      - 정밀도 높이면 재현율 떨어짐, 재현율 높이면 정밀도 떨어짐(Trade-off)

## 성능 검증
- 데이터 분리 방법, 하이퍼파라미터(학습률)을 어떻게 설정했는 지에 따라 점수 달라질 수 있음
- 어떤 방식이 좋은 성적을 받을 수 있는 지 검증(학습률 조절하면서 등)
- 검증을 테스트 데이터로 진행하면, **데이터 유출** 발생
- 검증 방식 분류
  - 검증 데이터(단순 분할 방식)
  - 교차 검증(Cross-Validation)
- 검증 데이터(Validation Data)

- 교차 검증
  - 훈련 데이터를 여러개의 덩어리로 나눈 뒤, 각 덩어리가 돌아가면서 한번 씩 **검증 데이터**역할을 하는 것
  - 검증 데이터를 일회성으로 사용하면 불안정성을 극복하기 위해, 여러 개의 검증 세트를 체계적으로 만들어 평가하는 방법
  - 마치 수능 전 여러 번 모의고사 보는 느낌


## 비지도 학습
- 정답이 없는 데이터의 숨겨진 구조나 규칙을 찾는 방법
- 수백 장의 동물 사진을 주고 **비슷한 것끼리 묶어 봐** 라고 하는 것
- 학습 유형
  - 군집화
    - 비슷한 데이터끼리 그룹으로 묶는 것
  - 차원 축소
    - 데이터의 복잡성(차원)을 줄여 핵심만 남기는 것
  - 연관(있다는 것만 알자)
    - 데이터 안에서 특정~
- 군집화(Clustering)
  - 정답이 없는 데이터들을 유사한 특징을 가진 것끼리 하나의 그룹(Cluster)으로 묶는 작업
  - 정답이 없어도 되기 때문에 레이블링(정답을 달아주는) 작업이 불필요
  - 정답이 없기 때문에 사람이 파악하지 못한 숨겨진 패턴을 찾을 수 있음
  - **군집화 알고리즘**
    - K-평균(K-Means)
      - 데이터들이 가장 가까운 중심점(Centroid)을 기준으로 뭉치도록 그룹을 형성하도록 하는 알고리즘
      - 동작 방식
        1. K개의 중심점을 데이터 공간에 랜덤으로 배치
        2. 모든 데이터는 자신과 가장 가까운 중심점과 그룹을 형성(K개의 그룹 생성)
        3. 각 그룹의 평균을 계산, 그 지점을 다시 중심정으로 설정
        4. 2, 3 과정을 **더 이상 변화 없을 때까지** 반복
      - 이상치 민감, 초기 중심점 위치에 따라 결과 달라질 수 있음
      - 군집 개수(K) 직접 지정
        - 너무 작게 잡으면, 다른 성격 묶일 수 있음
        - 너무 크게 잡으면, 같은 그룹 여러 개 쪼개질 수 있음
      - 추가정보 ->
      - 엘보우 방법
        - 적절한 K 값을 선택하는 방법
        - K를 1부터 10까지 늘려가며 **이너셔**를 계산(10 넘어가는 순간 학습 복잡해짐으로 의미 없어짐)
          - 이너셔란
            - 각 데이터 포인트가 자신이 속한 클러스터의 중심점에서 얼마나 떨어져 있는지, 그 거리의 총합
            - 이너셔가 작을수록 데이터들이 잘 뭉쳐있음을 나타냄
            - 완만해지는 타이밍이 가장 적합한 순간
      - 실루엣 스코어
        - 각 데이터들이 다른 그룹과의 가까움에 따라서 점수를 매김
- 계층적 군집(Hierarchical)
  - K 값을 미리 정하지 않아도 되는 군집
  - 데이터 간의 거리를 바탕으로 가까운 것부터 순서대로 묶어 나가면서 나무 형태의 구조를 만들어가는 방식
- 차원 축소
  - 데이터의 중요한 정보는 최대한 유지하면서, 불필요한 특징을 제거
  - 차원의 저주
    - 데이터의 차원(특징의 개수)이 증가할수록, 데이터를 분석하는데 필요한 공간의 부피가 기하급수적으로 커져 발생하는 문제
    - 문제점
      - 불필요한 정보(노이즈)가 많아져 모델의 예측 성능 떨어질 수 있음
      - 모델이 너무 복잡해져 과적합(Overfitting)이 될 가능성이 높아짐
      - 계산할 것이 너무 많아져 모델 학습에 많은 시간이 걸림
      - 3차원을 넘어서면서 시각화하기 어려움
  - 방법
    - 특성 선택
      - 여러 특징 중 가장 중요하다고 생각되는 몇 개의 특징만 골라내는 방식
    - 특성
      - **PCA**
        - 데이터가 가장 넓게 퍼져있는(분산이 가장 큰) 방향으로 새로운 축을 찾는 기술
        - 새로운 축이 바로 데이터의 정보를 가장 잘 설명(정보를 가장 많이 포함)하는 제1 주성분
        - 주성분과 직각을 이루는 축이 제2 주성분

## 참고
- ROC Curve
  - 다양한 임계값 변화에 따라 성능이 어떻게 달라지는지 (성능지표를)시각적으로 보여주는 그래프
    - FPR
    - TPR
    - AUC
  - 1에 가까울 수록 좋음, 0.5이면 랜덤 돌리는게 나을 수도?
  - 0.8이상이면 좋다고 판단