{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c7a3a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "- 머신러닝\n",
    "    - 학습 종류\n",
    "        - 지도 학습\n",
    "            - 정답지가 있음\n",
    "            - 회귀:\n",
    "                - 연속적인 숫자 값을 예측\n",
    "                - 선형 회귀\n",
    "            - 분류\n",
    "                - 특징을 통해 분류 \n",
    "                - 로지스틱 회귀 (이진 분류)\n",
    "                    - 선형회귀 모델 + 시그모이드 함수(0 ~ 1) + 이진 교차 엔트로피(틀린 답에 확신하면 강한 오차)\n",
    "                - 소프트맥스 회귀 ( 다중 분류)\n",
    "                    - 선형회귀 + 소프트맥스(모든 클래스 확률 총합이 1) + 범주형 교차 엔트로피(정답 확률값에만 집중)\n",
    "        - 비지도 학습\n",
    "            - 정답지가 없음\n",
    "            - 군집화\n",
    "                - 비슷한 데이터끼리 묶기\n",
    "                - K-means: 데이터들이 중심점을 기준으로 그룹을 형성하도록 함\n",
    "                - 계층적 군집: K값을 미리 정하지 않고, 거리를 기준으로 가까운 순으로 묶는 방법\n",
    "            - 차원 축소\n",
    "                - 데이터의 복잡성을 줄여서 핵심만 남김\n",
    "                - 차원의 저주(데이터가 많으면 과적합, 성능 , 학습시간이 문제)를 해결\n",
    "                - PCA\n",
    "        - 강화 학습\n",
    "            - 상과 벌을 통해 학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860808e5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "최소 제곱법\n",
    "- 예측 모델에서 비용(최소 제곱 오차)을 최소화하는 가중치와 편향을 찾는 원리 \n",
    "- 정규 방정식: \n",
    "    - 복잡한 방정식을 한 번에 계산 \n",
    "    - 역행렬이 없으면 계산할 수 없음\n",
    "    - 특이값 분해로 해결 \n",
    "- 경사 하강법:\n",
    "    - 최적의 파라미터를 점직적으로 찾아가는 방법 \n",
    "    - 비용 함수의 기울기가 0이 되는 지점을 찾는 것\n",
    "    - 이터레이션(한 걸음), 에포크(전체 데이터 훑기), \n",
    "    - 학습률(보폭), 허용 오차(학습 조기종료 조건), 배치 크기(계산 묶음)\n",
    "    - 배치 경사 하강법(전체 데이터), 확률적 경사 하강법(1개), 미니배치 경사 하강법(적당히)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66de11fd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "데이터 EDA\n",
    "- 모든 프로젝트의 첫 과정 \n",
    "- 분석의 방향성, 모델의 성능 향상(문제점 파악), 새로운 인사이트 발견\n",
    "- 데이터 로드 -> 정제 및 전처리 -> 개별 변수 분석 -> 변수 간 관계 분석 -> 분석 결과 정리 \n",
    "\n",
    "상관 관계\n",
    "- 두 변수가 함께 변화하는 관련성 \n",
    "- -1 과 1 사이의 값을 가짐\n",
    "- 양의 상관관계(두 변수가 같이 증가), 음의 상관관계(두 변수가 같이 감소), 상관관계 없음(관련 X )\n",
    "- 상관관계가 높다고 해서 인과관계가 있다는 것은 아님 \n",
    "\n",
    "데이터 시각화\n",
    "- Matplotlib\n",
    "    - 파이썬 시각화 라이브러리의 근간\n",
    "    - 세부적인 요소, 크기, 레이아웃을 설정\n",
    "- Seaborn\n",
    "    - 통계적으로 의미 있는 그래프를 쉽게 만들어주는 라이브러리 \n",
    "    - Matplolib을 기반으로 동작 \n",
    "- Matplotlib을 기반으로 제목/축/라벨등을 추가하고, Seaborn으로 데이터를 그래프로 그림\n",
    "\n",
    "데이터 시각화 그래프 종류\n",
    "- 히스토그램\n",
    "    - 막대 그래프로 표현하며, 하나의 데이터 분포를 파악하기 위해 사용\n",
    "- 박스 플롯\n",
    "    - 사분위수를 사용하며, 이상치를 파악하기 위해 사용 \n",
    "    - 사분위수\n",
    "        - 25, 50, 75% 를 구하는 것\n",
    "        - 이상치: 25% - 1.5*(IQR(75% - 25%))\n",
    "- 산점도\n",
    "    - 두 변수 사이에 점을 찍는 그래프\n",
    "    - 패턴이나 이상치를 쉽게 찾을 수 있음\n",
    "    - 데이터가 많으면 파악하기 어렵고, 상관관계를 보여줄 뿐, 인과관계를 증명하지 않음\n",
    "- 히트맵\n",
    "    - 여러 숫자형 변수들 간의 크기를 색상으로 변환해서 보여주는 것 \n",
    "    - 상관관계 분석에 많이 사용 됨 \n",
    "- 페어 플롯\n",
    "    - 여러 변수들 간의 관계를 한 번에 보여주는 그래프 \n",
    "    - 변수들 사이의 관계와 분포를 한 번에 보기 좋음 \n",
    "    - 복잡해질 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c026fa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "모델 학습\n",
    "- 데이터 분리 \n",
    "    - 학습한 결과를 확인하기 위해서 데이터를 학습 데이터와 테스트 데이터로 분리해야 함 \n",
    "    - train_test_split(훈련/테스트 데이터 분리), stratify=y(클래스를 같은 비율로 분리)\n",
    "    - 과적합\n",
    "        - 훈련 데이터에만 너무 익숙해져서 잡음(노이즈)까지 외워버리는 현상 \n",
    "        - 훈련 데이터에는 좋은 성능을 보이지만, 테스트 데이터에는 낮은 성능 \n",
    "    - 과소적합\n",
    "        - 모델이 너무 단순해서 훈련 데이터의 핵심 패턴조차 학습하지 못함 \n",
    "        - 훈련 데이터에서도 낮은 성능, 테스트 데이터에서도 낮은 성능 \n",
    "\n",
    "- 데이터 전처리\n",
    "    - 스케일링\n",
    "        - 표준화\n",
    "            - 데이터의 평균 0, 표준편차 1로 변환 \n",
    "            - 이상치에 덜 민감하고, 정규분포에 따를 떄 효과적 \n",
    "            - 모든 특성에 공평한 영향력을 부여 \n",
    "            - (주의) 데스트 데이터의 표준화는 반드시 \"훈련 데이터의 평균/표준편차\"를 활용해야 함\n",
    "        - 정규화\n",
    "            - 0 ~ 1 값으로 축소 \n",
    "            - 이상치에 민감 , 최소/최대값을 알아야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb098a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "모델 평가\n",
    "- 선형 회귀\n",
    "    - MSE(평균 제곱 오차)\n",
    "- 분류 \n",
    "    - 정량적인 수치로 평가 \n",
    "    - 정확도\n",
    "        - 맞은 예측 개수 / 전체 예측 개수\n",
    "        - 불균형 데이터에서는 성능 평가 지표로 사용하기 어려움\n",
    "    - 혼동 행렬\n",
    "        - 분류 모델의 성능 평가를 할 떄 사용하는 가장 기본적인 도구 \n",
    "        - TP / TN / FP / FN\n",
    "    - 정밀도\n",
    "        - 모델이 \"Positive\" 라고 예측한 것들 중에서 진짜 \"Positive\"의 비율\n",
    "        - 모델이 얼마나 정교한지를 나타냄 \n",
    "    - 재현율\n",
    "        - 실제 “Positive” 중에서 모델이 “Positive”라고 맞춘 비율\n",
    "        - 모델이 하나라도 놓치면 안될 때 중요\n",
    "    - 조화 평균\n",
    "        - 정밀도와 재현율을 모두 고려 (2 * 재현율 * 정밀도) / (재현율 + 정밀도)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b7a4e9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "성능 검증 \n",
    "- 평가한 데이터가 정말 신뢰성이 있는지 확인하기 위해서 데이터를 잘 나눴는지, 파라미터는 잘 설정했는 지 확인하는 과정 \n",
    "- 훈련/테스트 데이터로 나눈 뒤, 훈련 데이터를 다시 훈련/검증 데이터로 나눠서 사용\n",
    "- 교차 검증(K-Fold)\n",
    "    - 훈련 데이터를 여러 개(K개)로 나눈 뒤, 각 폴드가 돌아가면서 한 번식 '검증 데이터' 역할을 하는 것\n",
    "    - 수능 전에 여러 번의 모의고사를 보는 것과 같음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c640840",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "딥러닝\n",
    "- 고전적인 머신러닝 학습 방법(복잡한 패턴 학습 불가, 비정형 데이터 처리 불가)를 극복한 방법\n",
    "- 인간의 뇌에서 영감을 받아서 만들어진 학습 방법론\n",
    "    - 퍼셉트론\n",
    "        - 인공 신경망의 기본적인 단위 \n",
    "        - 입력/가중치/활성화 함수 로 구성\n",
    "- 신경망(얕은)\n",
    "    - 입력/은닉/출력 계층으로 이루어짐\n",
    "    - 은닉층이 하나만 있고, 은닉층에서는 여러 개의 퍼셉트론이 있음 \n",
    "- 심층 신경망\n",
    "    - 은닉층을 여러 개(깊게) 쌓는 방식\n",
    "    - 특징을 알려주지 않아도, 복잡한 패턴을 스스로 발견함\n",
    "\n",
    "MLP(다중 퍼셉트론, Multi-Layer Perceptron)\n",
    "- 인공 신경망의 한 종류로, 퍼셉트론을 여러 층으로 쌓은 모델\n",
    "- 학습 과정\n",
    "    1. 순전파(Forward Propagataion)\n",
    "        - 데이터가 입력층 -> 은닉층 -> 출력층을 지나가면서 최종 예측값을 도출\n",
    "        - 초기에는 가중치를 랜덤으로 설정\n",
    "    2. 손실 함수 계산(Loss Function)\n",
    "        - 순전파 과정에서 나온 예측값과 실제 정답값을 비교해서 오차를 구함 \n",
    "        - 회귀(평균 제곱 오차), 분류(교차 엔트로피), 비지도(클러스터링 후 떨어진 거리의 총합)\n",
    "    3. 역전파(Back Propagation)\n",
    "        - 손실 값을 가지고, 출력층에서 거꾸로 게산하면서 가중치를 업데이트하는 과정\n",
    "    4. 가중치 업데이트\n",
    "\n",
    "    - 위 과정을 정해진 학습 횟수(에포크) 만큼 반복하던가, \n",
    "    - 조기 종료(Early Stopping), 오차가 떨어지면 중간에 중단 \n",
    "- 학습 성능 향상\n",
    "    - 활성화 함수(RELU)\n",
    "        - 0보다 작으면 0, 0 보다 크면 그대로 출력 \n",
    "        - 기울기 소실 문제를 해결하며, 빠른 계산 속도\n",
    "    - 옵티마이저\n",
    "        - 손실 함수의 값이 최소가 되는 최적의 가중치를 찾는 알고리즘\n",
    "        - 경사 하강법이 대표적이며, 학습률이 높으면 오버슈팅, 학습률이 낮으면 지역 최저점에 빠짐\n",
    "        - 가장 많이 쓰이는 방식이 Adam(관성과 적응적 학습률)\n",
    "    - 규제\n",
    "        - 모델의 과적합을 막기 위해 제약을 거는 것\n",
    "        - L1\n",
    "            - 일부 가중치를 0으로 만들어 복잡도를 감소\n",
    "            - 불필요한 특성이 많은 경우 사용\n",
    "        - L2\n",
    "            - 가중치를 0에 가깝게 만듬(0으로 만들지는 않음)\n",
    "            - 다중공선성(두 변수가 서로 강하게 상관) 있는 경우 사용\n",
    "        - 드롭아웃\n",
    "            - 학습 시 각 뉴런을 랜덤하게 일시적으로 학습시키지 않음\n",
    "            - 편향 학습, 특정 뉴런에 의존 방지\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c060789d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "(2-1) 임베딩 / 토큰화 / RNN \n",
    "- 원-핫 인코딩\n",
    "    - (워드 임베딩) 범주형 데이터를 숫자형 벡터로 변환하는 방법\n",
    "    - 장점: **순서 없음**\n",
    "    - 단점\n",
    "        - **차원의 저주: 차원이 커지면 데이터가 희소해서 활용이 어려움**\n",
    "        - **유사성 표현 불가: 비슷한 단어라도 유사한 벡터로 표현되지 않음**\n",
    "- Word2Vec\n",
    "    - 각 단어와 그 주변 단어들 간의 관계를 예측\n",
    "    - CBOW(Continuous Bag of Words)\n",
    "        - 주변 단어를 가방에 담아 하나의 단어를 예측\n",
    "        - 장점: 학습 속도가 빠름, 자주 나오는 단어에 강함\n",
    "        - 단점: 희귀 단어 표현에 약함\n",
    "    - Skip-gram\n",
    "        - 중심 단어를 이용해 주변 단어를 예측\n",
    "        - 장점: 적은 데이터도 잘 동작, 희귀 단어에 강함\n",
    "        - 단점: 학습 속도가 느림\n",
    "- RNN\n",
    "    - 순차적 데이터를 처리하는 학습\n",
    "    - 각 시점마다 동일한 가중치를 사용\n",
    "    - 한 번에 하나의 요소를 처리\n",
    "    - hidden state를 유지하면서, 가변 길이 데이터를 처리할 수 있음\n",
    "    - RNN의 출력은 과거 입력에 영향을 받음\n",
    "    - **한계: 기울기 소실 문제(장기 의존성 학습이 어려워지는 현상)**\n",
    "- LSTM\n",
    "    - 기울기 소실 문제를 해결하기 위해 제안된 RNN의 한 종류\n",
    "    - cell state를 이용해서 장기 기억\n",
    "        - Forget gate: 이전 cell state에서 무엇을 버리고, 유지할지 결정\n",
    "        - input gate: 새 정보 중 얼마나 cell state에 쓸지 결정\n",
    "        - output gate: cell state 중 얼마나 hidden state로 내보낼지 결정\n",
    "- N-gram 언어 모델\n",
    "    - N개의 단어 묶음을 기반으로 다음 단어를 예측하는 통계적 LLM\n",
    "    - 장점: 간단\n",
    "    - 단점: N이 커지면 예측 성능이 떨어짐, 장기 의존성 약함\n",
    "- Seq2Seq\n",
    "    - 하나의 시퀀스(입력)을 다른 시퀀스(출력)으로 변환하는 딥러닝 모델\n",
    "    - 인코더-디코더\n",
    "    - 주로 번역에 활용\n",
    "- Teacher Forcing\n",
    "    - Seq2Seq 모델을 학습시키는 데 사용되는 기술\n",
    "    - 학습 과정에서 예측값이 아닌, 정답을 강제로 넣어서 학습을 안정적으로 하는 기술\n",
    "- Beam Search\n",
    "    - 탐욕적으로 다음 후보를 선택하는 것이 아닌, 여러 후보 중에서 동시 탐색\n",
    "- Bottleneck problem\n",
    "    - Seq2Seq는 마지막 hidden state에 문장의 모든 의미 정보를 담는데, 압축하다보니 생기는 정보 손실을 의미\n",
    "- Attention\n",
    "    - 입력 데이터의 특정 부분에 더 집중하여 중요한 정보를 찾아내는 메커니즘\n",
    "    - Softmax\n",
    "    - Bottlenect problem 해결, 기울기 소실 문제 해결\n",
    "    - 효과1 : 모델의 의사결정 과정을 해석할 수 있음\n",
    "    - 효과2: 단어와 단어 간의 매핑 관계를 자연스럽게 학습 (정렬)\n",
    "    - decoder의 hidden state: Query  // encoder의 hidden state: value\n",
    "    - Attention 과정\n",
    "        1. Query와 Values 사이 유사도 계산 \n",
    "        2. Softmax를 통해 확률 분포 얻기\n",
    "        3. 분포를 이용해 values 를 가중합 \n",
    "- self-attention\n",
    "    - 하나의 시퀀스 내에서 단어들이 서로 어떤 관계를 가지는지 파악하는 어텐션 메커니즘\n",
    "    - 장점1) 연산 수가 시퀀스 길이에 따라 증가하지 않음\n",
    "    - 장점2) 모든 단어가 각 층에서 직접 상호작용(최대 상호작용 거리=1)\n",
    "    - 단어 표현 방법\n",
    "        - Query 벡터: 단어 i가 다른 단어로부터 어떤 정보를 찾을지를 정의\n",
    "        - Key 벡터: 단어 i가 자신이 가진 정보의 특성을 표현\n",
    "        - value 벡터: 실제로 참조되는 정보 내용을 담고 있는 벡터\n",
    "    - 한계1) 순서 정보 부재 (유사도만 계산하기 때문)\n",
    "        - 해결1) Positional Encoding(위치 벡터)\n",
    "    - 한계2) 비선형성 부족\n",
    "        - 해결2) Feed-Forward Network\n",
    "        (각 단어 출력 벡터에 Fully Connected + ReLU 을 추가해 비선형 표현으로 확장)\n",
    "    - 한계3) 미래를 참조하는 문제(모든 단어를 동시에 보기 때문에, 생성되지 않아야 할 미래 단어를 참조)\n",
    "        - 해결3) Masked Self-Attention(미래 단어에 해당하는 항목을 가림)\n",
    "- transformer\n",
    "    - 셀프 어텐션 메커니즘을 사용하여 시퀀스 데이터를 처리하는 딥러닝 모델\n",
    "    - encoder-decoder 구조 + 병럴로 속도가 빠르다\n",
    "- Multi-Headed Attention\n",
    "    - 문장에서 같은 단어라도 다른 단어로 파악될 수 있고, Self-Attention head로는 한 가지 관점에서의 관계만 파악할 수 있음\n",
    "    - 이를 해결하기 위해, 다양한 관점에서 동시에 정보를 파\n",
    "- Scaled Dot Product\n",
    "    - Query와 Key의 차원이 커질수록, 내적값도 커지는데, 스케일 조정\n",
    "- Residual Connection (잔여 연결)\n",
    "    - 입력 데이터를 다음 레이어의 출력에 직접 더해주는 방식\n",
    "    - 기울기 소실 문제를 해결하고, 깊은 신경망을 효율적으로 학습\n",
    "- Decoder\n",
    "    - 압축한 정보를 바탕으로 새로운 시퀀스를 생성하는 부분\n",
    "    - 구성\n",
    "        - Maked Self-Attention: 미래 단어에 마스크를 씌운 Multi head self attention\n",
    "        - Add & Norm: 잔차 연결(입력 데이터를 다음 레이어의 출력에 그대로 더하기) \n",
    "        + 레이어 정규화(평균 0, 분산 1)\n",
    "- encoder\n",
    "    - 양방향 문맥을 모두 활용\n",
    "    - decoder와의 차이는 masking을 제거한 것 뿐\n",
    "- Encoder 모델\n",
    "    - BERT(대표 모델), 양방향 문맥을 모두 활용\n",
    "    - 학습방법1) Masked LM(마스크된 단어에만 집중하지 않고, 다양한 문맥 표현을 학습해 강건) - 나머지 토큰\n",
    "    - 학습방법2) NSP(Next Sentence Prediction, 두 문장이 이어지는 관계인지 판별) - CLS 토큰\n",
    "    - 한계1) 시퀀스를 생성하는 테스크에 적합하지 않음(번역, 텍스트 생성)\n",
    "- In-Context Learning\n",
    "    - LLM에서 별도의 모델 업데이트 없이, 프롬프트에 제공된 예시만으로 특정 작업을 수행\n",
    "- Chain-of-Thought Prompting(CoT)\n",
    "    - 해결 과정을 단계별로 명시하여 추론 능력을 향상시키는 기법\n",
    "- Zero-Shot-Chain-of-Thought prompting\n",
    "    - 별도의 예시 없이 단지 ‘단계별로 생각하자’와 같은 지시를 추가하여 추론 능력을 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8313ddf6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "(3-1)이미지 처리\n",
    "- FCN 모델(Fully-Connected Layer)\n",
    "    - 신경망의 각 레이어가 이전 레이어의 모든 뉴런과 연결된 가장 기본적인 신경망 모델\n",
    "    - ex) 32*32*3 이미지 ⇒ 가중치 ( 3072 * 1 )\n",
    "- CNN 모델(Convolutional Neural network)\n",
    "    - 주로 이미지 처리 및 컴퓨터 비전에서 사용되는 딥러닝 모델\n",
    "    - CNN 레이어는 “**지역 정보**”를 추출하는 데 유리하게 설계\n",
    "    - 합성곱(Convolution)\n",
    "        - **이미지의 특징을 효과적으로 추출하기 위한 필터 연산**\n",
    "        - 필터(작은 크기의 행렬, 패턴을 담고 있음) → 슬라이딩(필터를 훑기)\n",
    "        - → 합성곱 연산(필터가 각 위치에서 겹치는 부분의 픽셀 값을 곱해서 모두 더함)\n",
    "        - → 특징 맵(Feature Map, 원본 이미지에서 감지하려는 특징이 어느 위치에서 얼마나 강하게 나타나는 지 보여주는 새로운 2D 데이터가 생성됨)\n",
    "        - “필터”는 항상 입력의 깊이/채널 축과 동일한 차원  ( **3***32*32 이미지, **3***5*5 필터)\n",
    "        - 출력 해상도 = 입력 해상도 - 필터해상도 + 1\n",
    "        (입력 해상도: 5*5, 필터 해상도: 3*3 ⇒ ((5-3)+1, (5-3)+1) ⇒ (3, 3)\n",
    "        - 입출력 해상도를 유지하는 방법\n",
    "            \n",
    "            ⇒ 입력 이미지의 가장자리에 0과 같은 값으로 채워진 테두리를 추가 \n",
    "            \n",
    "            비선형 블록(Conv[Linear] + ReLU(비선형 변환))과 함께하면 모델링 파워 향상 \n",
    "            \n",
    "    - 풀링(Pooling)\n",
    "        - **합성곱을 거친 특징 맵의 크기를 줄여주는 과정**\n",
    "        - **효율적 연산 및 위치 변화의 강겅선 확보**\n",
    "        - **핵심정보는 유지하면서 데이터의 양을 줄여 계산 효율성을 높이는 역할**\n",
    "        - 과적합 방지: 핵심적인 특징만 남기기 때문에 사소한 부분까지 과도하게 학습하는 것을 막음\n",
    "    - Fully Connected Layer(완전 연결 계층)\n",
    "        - CNN의 최종 의사결정자 역할(핵심 특징들을 종합하여 최종적으로 분류하는 역할)\n",
    "        - 1차원 데이터로 펼치기(Flatten) → 특징 종합 및 분류(가중치 부여)\n",
    "        - → 최종 확률 출력(소프트맥스와 같은 활성화 함수)\n",
    "    - 수용 영역\n",
    "        - CNN이 이미지를 처리하면서 한 번에 볼 수 있는 영역의 크기\n",
    "        - 네트워크가 깊어질수록 수용영역도 넓어짐 → 폭 넓은 맥락 이해 가능\n",
    "    - 스트라이드(Stride) 합성곱\n",
    "        - 합성곱 필터가 이미지를 풅을 때 이동하는 간격을 조절하는 기술\n",
    "        - 차원 축소 및 계산 효율성을 위해 사용\n",
    "        - 스트라이드 합성곱을 적용했을 때의 출력 해상도\n",
    "            - 출력해상도 = (입력 해성도 + (2 * 패딩) - 필터 해상도) / 스트라이드  + 1\n",
    "    - 풀링 vs 스트라이드 합성곱\n",
    "        - 풀링은 학습 상수가 없지만, 스트라이드는 커널을 동시에 학습\n",
    "- AlexNet\n",
    "    - 5개의 합성곱 계층과 3개의 완전연결 계층으로 구성된 8계층 CNN 모델\n",
    "    \n",
    "    - 출력 채널 사이즈(W’) : (W - K + 2P) / S + 1 = (227 - 11 + 4 ) / 4 + 1 = 56\n",
    "    - 출력량(메모리)\n",
    "        - C * H’ * W’ = 64 * 56 * 56  ,  H와 W는 높이와 너비, 동일하게 계산\n",
    "    - 상수(매개변수) 갯수\n",
    "        - 가중치 + 편향 = (필터 개수 * 입력 채널 * 커널사이즈^2) + 필터 개수(편향은 각 필터에 하나씩 존재)\n",
    "    - FLOPS\n",
    "        - 출력량 * (채널 * 커널 사이즈^2) = 200,704 * 363\n",
    "- VGGNet\n",
    "    - 각 블록당 맥스 풀링, ReLU, 16개의 합성곱/연결층 레이어, 소프트맥스 수행\n",
    "    - “작고 단순한 필터를 깊게 쌓으면 성능이 좋아진다!’\n",
    "- ResNet\n",
    "    - 잔차 연결을 사용하여 매우 깊은 신경망을 효율적으로 학습시키는 합성곱 신경망\n",
    "    - 과소적합이 문제!\n",
    "- MobileNet\n",
    "    - 모바일 및 임베디드 장치와 같이 제한된 컴퓨팅 자원을 가진 환경에서 효율적으로 작동하도록 설계된 경량 CNN 모델\n",
    "    - 공간과 채널을 두 단계로 분리하여 처리\n",
    "        - 깊이별 합성곱: 각 채널별 독립적 3*3 합성곱 수행\n",
    "        - 화소별 합성곱: 1*! 합성곱을 채널방향으로 적\n",
    "- ViT\n",
    "    - Transformer 아키텍쳐를 CV 분야에 적용한 딥러닝 모델\n",
    "    - 이미지 분할 → 임베딩 벡터로 변환 → 위치 정보 추가(positional encoding) → 트랜스포머 인코더 적용(어텐션 메커니즘, 이미지의 모든 패치 간의 관계를 학습) → 분류\n",
    "    - 장점\n",
    "        - **전역 문맥**을 한 번에 고려 가능\n",
    "        - 시퀀스 데이터의 경우, **순서 고려** 가능\n",
    "    - 단점\n",
    "        - **대규모 학습 자원 필요**\n",
    "        - 학습 데이터 규모가 작을 경우, CNN보다 성능 저하\n",
    "        - 한번에 고려할 수 있는 토큰이 제한적\n",
    "    - 활용\n",
    "        - 이미지 **분류**/탐지/**분할**/생성에서 모두 고성능\n",
    "- 증류학습\n",
    "    - 크고 복잡한 모델의 지식과 능력을 작고 효율적인 모델에게 전달하는 학습 기법\n",
    "- 전이 학습(transfer Learning)\n",
    "    - 한 문제를 해결하기 위해 학습된 모델을 다른 새로운 문제에 재사용하는 머신러닝 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a70ba",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "3-2 이미지 생성\n",
    "\n",
    "- 파운데이션 모델\n",
    "    - 세가지 접근 방식\n",
    "        - Zero-shot : 예시 없이 질문만 던져서 문제 해결, 사전 학습 모델이 배경 지식\n",
    "        - Few-shot: 예시 몇 개를 함께 제시하여 문제 해결\n",
    "        - Fine-tuning: 새 task에 맞춰 실제 추가 학습 진행, 모델 자체가 바뀜\n",
    "- AGI (Artificial General Intelligence)\n",
    "    - 인간이 수행할 수 있는 모든 지적 작업을 성공적으로 수행할 수 있는 가상의 인공지능\n",
    "    \n",
    "- CLIP\n",
    "    - OpenAI 가 개발한 신경망 모델\n",
    "    - 텍스트 인코더(트랜스포머 구조, Encoder Only 구조)\n",
    "    - 이미지와 텍스트를 같은 **임베딩 공간에 투영**하여 유사도를 계산하는 모델\n",
    "    - 제로샷 학습: 직접 보지 못한 새로운 카테고리도 분류 가능\n",
    "- 멀티모달\n",
    "    - 서로 다른 두 가지 이상의 모달리티(이미지와 텍스트) 간의  공통된 임베딩 벡터 공간을 연결\n",
    "- SigLIP\n",
    "    - CLIP이 사용하는 소프트맥스 기반의 손실 함수 대신 시그모이드 손실 함수를 사용\n",
    "    - 배치 크기에 독립적(각 쌍을 독립적으로 처리)\n",
    "    - 작은 배치 크기에서도 뛰어난 성능\n",
    "- LLaVA(Large Language and Vision Assistant)\n",
    "    - vision과 language 모델을 결합한 모델로, 텍스트와 이미지를 동시에 이해\n",
    "    - 효율적인 메모리, 다중 모달 학습 ,파인 튜닝\n",
    "- sVLM\n",
    "    - 이미지와 텍스트를 동시에 처리할 수 있는 효율적인 멀티모달 모델\n",
    "    - OpenVLM, sVLM, SmolVLM, Moondream 0.5B, Gemini Nano, InternVL, LMDeploy\n",
    "- 파운데이션 모델(LLM)\n",
    "    - 3가지 구성요소\n",
    "        1. 빅데이터 ⇒ 데이터가 증가할수록 성능이 증가\n",
    "        2. 자가 학습(Self-supervised Learning): 사람이 정답을 알려줄 필요 X, \n",
    "        (ex: 다음 토큰을 예측을 통한 텍스트 파운데이션 모델 학습)\n",
    "        3. 어텐션(Attention) 기반 트랜스포머(Transformer) 모델\n",
    "            - 더 많은 데이터를 학습할 수 있는 인공신경망 구조\n",
    "            \n",
    "    - (1)텍스트 파운데이션 모델\n",
    "        - GPT-1 , BERT 와 같은 언어 모델에도 3가지 구성 요소가 포함되어 있지만 성능이 저조\n",
    "        - GPT-2: 언어 모델이 추가 학습 없이도 텍스트 지시를 통해 새로운 테스크를 어느 정도 수행함\n",
    "        - 특이점 2가지\n",
    "            1. 규모의 법칙(Scaling Law): 더 많은 데이터, 큰 모델, 긴 학습 ⇒ 더 좋은 성능 \n",
    "            2. 창발성(Emergent Property): 특정 규모를 넘어서면 갑자기 모델에서 발현되는 성질\n",
    "                - ex1) 인-컨텍스트 학습(in-context Learning): 주어진 설명과 예시만으로 새로운 테스크를 수행\n",
    "                - ex2) 추론(reasoning) 능력\n",
    "        - 폐쇄형 LLM\n",
    "            - ChatGPT, Claude, Gemini\n",
    "            - 장점: 우수한 성능, 최신 기능\n",
    "            - 단점: 사용 시 마다 비용 발생, 모델이나 출력에 대한 정보가 제한적으로 제공\n",
    "        - 개방형 LLM\n",
    "            - LLaMA, Gemma, Qwen\n",
    "            - 장점: 무료, 모든 정보가 공개되어 있음\n",
    "            - 단점: 충분한 계산 자원이 필요, 상대적 성능이 낮음\n",
    "    - (2) 거대 언어 모델의 학습\n",
    "        - 다음 토큰 예측 기반 LLM\n",
    "        - 한계\n",
    "            - 사람의 지시에 대해 올바르지 않은 응답을 생성하거나, 유해한 응답을 생성할 수 있음\n",
    "        - 한계 극복 방법\n",
    "            - 정렬(Alignment) 학습\n",
    "                - LLM의 출력이 사용자의 의도와 가치를 반영하도록 하는 것\n",
    "                - 지시 학습(instruction tuning)\n",
    "                    - 주어진 지시에 대해 어떤 응답이 생성\n",
    "                    - 학습 방법 자체는 기존 언어 모델에서의 **지도 추가 학습**\n",
    "                    - 핵심 아이디어: 많은 데이터를 “지시”와 함께 학습\n",
    "                    - 성능 향상의 핵심 요소\n",
    "                        - 학습 테스크(데이터)의 개수\n",
    "                        - 추가 학습하는 모델의 크기: 특정 규모 이하에서는 지시 학습의 효과가 떨어짐\n",
    "                        - 지시를 주는 방법: 자연어 지시로 대화하듯 지시하는 것이 효과적\n",
    "                - 선호 학습(preference learning)\n",
    "                    - 지시 학습의 한계\n",
    "                    (정답이 정해진 경우에는 자연스럽지만, 정답이 없는 경우네는 한계가 있음)\n",
    "                    - 다양한 응답 중 사람이 더 선호하는 응답을 생성하도록 추가 학습\n",
    "                    - ChatGPT를 만들기 위한 핵심 알고리즘\n",
    "                    - InstructGPT\n",
    "                        - 사람의 피드백을 통한 강화학습(RLHF, Reinforcement Learning form Human Feedback)\n",
    "                        - 학습 과정\n",
    "                            1. 지시 학습을 통한 텍스트 파운데이션 모델의 추가 학습\n",
    "                            2. 사람의 선호 데이터를 수집하여, 보상 모델(Reward Model, RM)을 학습\n",
    "                            3. 보상이 높은 응답을 생성하도로 강화 학습을 통해 추가 학습\n",
    "                            (사람의 추가 개입 없이 학습된 모델들을 통해 추가 학습)\n",
    "                            \n",
    "                        - 학습 성능, 안전한 응답 모두 성능이 향상됨\n",
    "                        \n",
    "                    \n",
    "            \n",
    "    - (3) LLM의 추론\n",
    "        - 디코딩 (Decoding) 알고리즘\n",
    "            - LLM의 자동회귀 생성(Auto-regressive Generation)\n",
    "                - 순차적 추론을 통한 “토큰별 생성”\n",
    "                - 출력을 다시 입력에 넣으면서 재귀적으로 생성\n",
    "                - EOS 토큰(CLS, SEP) or 사전에 정의된 토큰 수로 “생성과중지”를 결정\n",
    "            - 목표\n",
    "                - 주어진 입력 x = [x1, x2, … , xn]에 대해 다음 토큰 x(n+1)을 생성\n",
    "            - Greedy Decoding\n",
    "                - 핵심 아이디어\n",
    "                    - 가장 확률이 높은 다음 토큰을 선택\n",
    "                - 장점\n",
    "                    - 사용하기 쉽다\n",
    "                - 단점\n",
    "                    - 직후만 고려하기 때문에 생성 응답이 최종적으로 최선이 아닐 수 있음\n",
    "                    - \n",
    "            - Beam Search\n",
    "                - 아이디어\n",
    "                    - 확률이 높은 k개(beam size)의 후보를 동시에 고려 (비동기)\n",
    "                    - 고르는 기준(누적 생성 확률)\n",
    "                - 장점\n",
    "                    - 최종적으로 좋은 응답 생성 확률이 높음\n",
    "                - 단점\n",
    "                    - 계산 비용이 많이 늘어남\n",
    "            - Sampling\n",
    "                - 아이디어\n",
    "                    - LLM이 제공한 확률에 비례해서 랜덤하게 생성\n",
    "                    - 다음에 나올 수 있는 토큰의 확률대로 랜덤하게 골라서 출력\n",
    "                - **Temperature 파라미터 조작**\n",
    "                    - 하이퍼 파리미터 T를 통해서 LLM이 생성한 확률 분포를 임의로 조작\n",
    "                    - T가 높으면 다양한 응답, T가 낮으면 높은 확률에 의존\n",
    "                    - 1보다 크면 전부 확률이 비슷비슷해진다.\n",
    "                - 장점\n",
    "                    - 다양한 응답이 생성될 수 있음\n",
    "                - 단점\n",
    "                    - 품질이 아쉬울 수 있음\n",
    "            - Top-K Sampling\n",
    "                - 아이디어\n",
    "                    - 확률이 높은 K개의 토큰들 중에서만 랜덤하게 확률에 따라 샘플링\n",
    "                - 장점\n",
    "                    - 품질이 낮은 응답을 생성할 가능성이 줄어듬\n",
    "                - 단점\n",
    "                    - 확률 분포의 모양에 상관 없이 고정된 k개의 후보군을 고려\n",
    "            - Top-P Sampling(or Nucleus Sampling)\n",
    "                - 아이디어\n",
    "                    - K를 고정하는 대신, 누적 확률(P)에 집중하여 K를 자동으로 조절\n",
    "                - 다양한 평가 지표에서 좋은 성능을 보임\n",
    "                - 업계 표준\n",
    "    - (4) LLM의 평가와 응용\n",
    "        - 평가(Evalutaion)\n",
    "            - 평가 방법\n",
    "                1. 사람이 임의의 정답을 작성 및 이와 예측을 비교(벡터 공간 유사도 측정 )\n",
    "                2. 정답과 무관하게 생성 텍스트 자체의 품질만을 측정\n",
    "                (Perplexity, PPL) ⇒ 얼마나 문장이 확률적으로 자연스러운지 측정 \n",
    "                3. 생성 텍스트의 “상대적 선호”를 평가 \n",
    "                    - LMArena, 가장 신뢰성 있는 방법 중 하나로 여겨짐\n",
    "                    - 높은 비용과 시간 ⇒ LLM-as-judge 로 해결\n",
    "                - LLM-as-judge(or G-Eval)\n",
    "                    - LLM을 통해 생성 텍스트를 평가\n",
    "                    - 한계점\n",
    "                        - 위치 편향: 특정 위치의 응답을 상대적으로 선호\n",
    "                        - 길이 편향: 품질과 상관없이 긴 응답을 선호\n",
    "                        - 자기 선호 편향: 생성 모델이 평가 모델에 따라 선호가 바뀜\n",
    "                    - 해결방법\n",
    "                        - 위치 편향: 순서를 바꿔서 두 번 평가하고 평균\n",
    "                        - 길이 편향: 길이가 미치는 영향을 통계적으로 제거\n",
    "                        - 자기 선호 편향 : 아직 고민중인 문제\n",
    "                \n",
    "        - 응용 및 한계\n",
    "            - 멀티모달 파운데이션 모델은 “다른 모달리티 데이터”를 LLM이 이해할 수 있도록 토큰화 및 추가 학습 하는 것 뿐!\n",
    "            - 합성 데이터 생성\n",
    "                - ex: Self-instruct: 175개의 데이터를 사람이 작성한 뒤, 합성 데이터를 생성 \n",
    "                ⇒ 사람이 만든 데이터와 비슷한 성능 달성\n",
    "                - Alpagasus\n",
    "                    - 프롬프팅을 통한 합성 데이터의 품질 평가 및 필터링 제안\n",
    "                    - 일정 점수를 넘는 데이터만 사용하자 ⇒ 성능 향상\n",
    "            - LLM의 한계\n",
    "                - 환각(Hallucination)\n",
    "                    - 사실과 다르거나, 지어낸 내용을 정확한 정보와 동일한 자신감과 유창함으로 응답을 생성\n",
    "                    - 원인\n",
    "                        - 사전 학습 데이터의 제한적인 범위가 환각 현상의 원인이 되기도 함\n",
    "                        - 아직도 활발한 연구 중\n",
    "                    - 해결방안\n",
    "                        - 검색 증강 생성(Retrieval-augmented Generation, RAG)로 해결 가능\n",
    "                - 탈옥(Jailbreaking)\n",
    "                    - 프롬프팅 엔지니어링을 통해 LLM의 정렬을 우회할 수 있음\n",
    "                    - ex) Do Anything Now(DAN) 프롬프팅\n",
    "                    - 원인\n",
    "                        - 여러 단계의 학습 과정에서 기인한 근본적인 한계로 인해 발생\n",
    "                    - 다양한 탈옥/방어 방법이 연구중\n",
    "                - AI 텍스트 검출\n",
    "                    - LLM의 무분별한 사용이 여러가지 문제를 야기\n",
    "                    - GPTZero ⇒ LLM이 만든 걸 탐지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cc62f3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "RAG\n",
    "- RAG(Retrieval-Augmented Generation)\n",
    "    - 검색 증강 생성\n",
    "- LLM이 문서를 이해하기 위해 필요한 것\n",
    "    - Chunking\n",
    "        - 컨텍스트 창(Context Window): LLM이 한 번에 처리할 수 있는 텍스트의 양\n",
    "        - 긴 문서를 Context Window에 맞는 작은 Chunk로 나눠서, 하나씩 집중해서 읽게 만들기 위해서\n",
    "        - Lost in the Middle: Context Window 내용이 너무 길어서 생기는 문제\n",
    "    - Parsing\n",
    "        - 문서에서는 다양한 데이터(텍스트, 표, 그림, …) 을 따로 뽑아내서 효율적으로 이해하고 활용하게 하기 위해서\n",
    "- 긴 텍스트를 다루는 방법\n",
    "    - 토크나이징(Tokenizing)\n",
    "        - `언어 이해 단위`\n",
    "        - LLM이 이해하는 작든 단위인 ‘토큰’으로 쪼개는 과정\n",
    "        - 문자와 토큰이 1:1로 대응하지 않음\n",
    "        - LLM은 토큰 단위로 텍스트를 읽고 처리하며, 모델마다 Context window가 정해져 있음\n",
    "    - 청킹(Chunking)\n",
    "        - `정보 검색 단위`\n",
    "        - 긴 텍스트 문서를 의미적으로 관련 있는 더 작은 청크 단위로 묶는 과정\n",
    "        - **RecursiveCharacterTextSplitter** 도구 사용\n",
    "            - 정해진 규칙에 따라 텍스트를 재귀적으로 분할\n",
    "            - 파라미터\n",
    "                - chunk_size: 각 청크의 최대 크기 지정\n",
    "                - chunk_overlap: 인접한 청크들 사이에 겹치는 크기를 지정\n",
    "                - length_function: 청크의 길이를 계산하는 방법(함수)을 지정\n",
    "                - is_separator_regex: 구분자를 정규표현식으로 해석할지 여부\n",
    "                - **`separators`**:  텍스트를 분할할 때 사용할 구분자들의 목록\n",
    "                \n",
    "- **RecursiveCharacterTextSplitter**\n",
    "    - 정해진 규칙에 따라 텍스트를 재귀적으로 분할(청크)\n",
    "    - 파라미터\n",
    "        - chunk_size: 각 청크의 최대 크기 지정\n",
    "        - chunk_overlap: 인접한 청크들 사이에 겹치는 크기를 지정\n",
    "        - length_function: 청크의 길이를 계산하는 방법(함수)을 지정\n",
    "        - is_separator_regex: 구분자를 정규표현식으로 해석할지 여부\n",
    "        - **`separators`**:  텍스트를 분할할 때 사용할 구분자들의 목록\n",
    "        \n",
    "- Langchain\n",
    "    - LLM Chain, 여러 구성 요소들을 결합하여 LLM의 출력을 생성하는 프로세스\n",
    "    - 입력 프롬프트를 모델에 전달, 모델의 출력을 받아 원하는 형식으로 처리할 수 있도록 구성된 파이프라인\n",
    "    - LangChain 종류\n",
    "        - Langchain Library\n",
    "            - langchain-core: LangChain의 가장 기본 문법\n",
    "            - langchain: 체인, 에이전트, .. 등을 제공하여 ‘두뇌’ 역할\n",
    "        - LangChain Templates\n",
    "            - 전체 코드 구조 생성, 일종의 템플릿\n",
    "        - LangServe\n",
    "            - REST API로 쉽게 배포할 수 있게 도와주는 도구\n",
    "        - LangSmith\n",
    "            - 디버그, 테스트, 모니터링을 도와주는 플랫폼\n",
    "        - LangGraph\n",
    "            - LLM이 가지는 여러 상태들을 관리하여 Agent를 구조화하는 프레임워크\n",
    "            - 등장 이유\n",
    "                \n",
    "                ![image.png](attachment:7bac9494-ecea-4ad6-80a7-1d6cde6ac841:image.png)\n",
    "                \n",
    "- LLM Chain 구성하는 법\n",
    "    1. LLM 정의\n",
    "    2. 프롬프트 정의\n",
    "    3. Chain 정의\n",
    "    4. Chain 호출\n",
    "- Parser\n",
    "    - StrOutputParser: 문자열만 나오게 하는 출력 파서\n",
    "    \n",
    "- RAG\n",
    "    - Retrieval-Augmented Generation(**검색, 증강된, 생성**)\n",
    "    - 외부 DB를 통해 검색한 정보를 추가로 제공하여 답변을 생성\n",
    "    - Vector Store\n",
    "        - 청크 데이터를 벡터로 변환하고, 이 벡터를 효율적으로 저장하고 검색하는 DB\n",
    "    - Retriever\n",
    "        - Vector Store에 저장된 벡터들 중에서 질문과 가장 관련이 깊은 벡터를 찾아주는 도구\n",
    "    - 처리 순서\n",
    "        1. 원본 문서(파싱)\n",
    "            - PDFLoader\n",
    "            - TextLoader\n",
    "        2. 정제된 텍스트(청킹)\n",
    "            - RecursiveCharacterTextSplitter\n",
    "        3. 텍스트 청크 리스트(인덱싱: 임베딩 & Vector Store 저장)\n",
    "            - UpstageEmbeddings: 임베딩\n",
    "            - Chorma.from_documents: 벡터 DB에 저장\n",
    "            - as_retriever(): 벡터 DB를 검색기로 변환\n",
    "        4. Vector Store(검색 가능한 벡터 데이터)\n",
    "- Chroma\n",
    "    - 벡터 데이터베이스\n",
    "- Retriever\n",
    "    - 사용자의 질문과 가장 관련성이 높은 문서를 찾아주는 도구\n",
    "    - 주요 동작 방식\n",
    "        - 질문 임베딩 → 유사도 검색 → 유사도 높은 결과(chunk)를 반환\n",
    "    - create_retriever_tool 함수 파라미터\n",
    "        - ‘retriever’ 객체 와 도구의 ‘name’\n",
    "- Langchain Tool\n",
    "    - AI 에이전트가 특정 작업을 수행하기 위해 사용하는 기능 or 외부 리소스에 접근하는 방법\n",
    "    - LLM 자체의 한계 극복, 실시간 정보, 특정 DB/외부 DB 접근, API 호출 등 다양한 작업\n",
    "- Multi-Agent\n",
    "    - 하나 이상의 에이전트들이 협력하여 복잡한 문제를 해결하는 시스템\n",
    "\n",
    "- 질문 프롬프트\n",
    "    \n",
    "    위 내용도 포함해서 퀴즈를 더 출제해줘.\n",
    "    \n",
    "    꼭 위에 있는 내용만 퀴즈에 나오는 게 아니라, 해당 내용에 있는 메인 주제들에 관련해서 시험에 나올만한 객관식 문제는 모두 내 줘.\n",
    "    \n",
    "    각 선택지가 매력적인 오답이 되도록, 다양한 기술들의 장점과 특징을 교모하게 섞여서 문제를 출제 해 줘.\n",
    "    \n",
    "- Instruction-tuning\n",
    "    - 언어모델이 사람이 내린 지시문을 따르도록 학습하는 단계\n",
    "    - 할루시네이션이 감소\n",
    "- MMLU(Massive Multitask Language Understanding)\n",
    "    - LLM의 성능을 평가하기 위한 벤치마크\n",
    "    - 초등학교 수준부터 전문가 수준까지 광범위한 분야의 다지선다형 문제 해결 능력을 통해 모델의 지식과 추론 능력을 평가한다.\n",
    "- RLHF ( Reinforcement Learning from human feedback)\n",
    "    - 인간 피드백 기반 강화 학습\n",
    "    - 작동 원리\n",
    "        1. 사전 훈련된 모델 준비\n",
    "        2. 보상 모델 학습 (인간 평가자가 점수를 부여한 데이터)\n",
    "        3. 강화 학습을 통한 미세 조정 \n",
    "    - 중요성\n",
    "        - 인간의 의도에 부합하는 답변 생성\n",
    "        - 유해성 및 편향 감소\n",
    "    - 주의점\n",
    "        - 인간 평가자의 편향\n",
    "        - 보상 해킹 ⇒ 정답의 여부와 관계없이 도움 되어 보이는 정답을 생성(할루시네이션)\n",
    "        \n",
    "- RLVR(Reinforcement Learning with Verifiable Reward)\n",
    "    - 검증 가능한 보상 기반 강화 학습\n",
    "    - 규칙 기반의 자동화된 검증기를 사용해 모델의 답변이 정확한지 판단하고, 보상을 줌\n",
    "- RAG(Retrieval-augmented Generation)\n",
    "    - 응답을 datastore에서 관련된 정보를 검색해서, 응답\n",
    "    - 구성요소\n",
    "        - Datastore: 가공되지 않은 대규모 텍스트 코퍼스 , 라벨링,구조화되지 않음\n",
    "        - query, index, language model\n",
    "- Sparse Retriever\n",
    "    - 키워드 일치 기반 검색\n",
    "    - 쿼리와 문서 간의 정확한 용어 일치(어휘적 유사도)\n",
    "- TF-IDF(Term Frequency-Inverse Document Frequency)\n",
    "    - Sparse Retriever\n",
    "    - 특정 단어가 얼마나 중요한지를 나타내는 통계적 수치\n",
    "    - TF: 단어가 얼마나 자주 등장하는 지\n",
    "    - IDF : 단어가 전체 코퍼스에서 얼마나 드물게 등장하는지\n",
    "    - 장점: 불용어(the, a) 문제 해결, 희소성 반영\n",
    "    - 단점: 의미를 고려하지 않음. 단순하게 빈도에 의존. 희소 행렬 문제\n",
    "- Dense Retriever\n",
    "    - 의미적 유사도 기반 검색\n",
    "    - 임베딩을 활용\n",
    "- Bi-encoder\n",
    "    - 질의와 문서를 각각 별대의 인코더로 벡터 변환하여 유사도를 측정하는 방식\n",
    "    - 대조 학습\n",
    "    - 장점: 빠르고 효율적, 의미적 유사성을 고려\n",
    "    - 단점: 정확도 한계 ( 질의와 문서가 서로 독립적으로 인코딩되기 때문에, 관계를 놓칠 수 있음)\n",
    "- cross-encoder\n",
    "    - 질의와 문서를 결합하여 한 번에 처리해 관련성을 판단하는 방식\n",
    "    - [CLS] 질의 [SEP] 문서 [SEP] 와 같은 형식으로 묶어서 입력\n",
    "    - 정확도가 높지만 ,느려서 실제로는 하이브리드 검색 시스템 2단계에 사용\n",
    "    - Bi-encoder / Sparse Retriever로 관련성 높은 문서를 찾고, cross로 재평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16aca6e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "PEFT\n",
    "- Unsloth\n",
    "    - LLM을 효율적으로 미세조정(Fine-tuning)하기 위한 라이브러리\n",
    "    - 수작업으로 유도된 수학 연산과 GPU 커널을 직접 작성할 수 있음\n",
    "    - 오픈 소스, 무료\n",
    "    \n",
    "- LoRA\n",
    "    - Low-Rank Adaptation\n",
    "    - LLM을 효율적으로 파인튜닝하는 기술\n",
    "    - 적은 수의 추가적인 매개변수만 학습시켜 모델의 성능을 향상시킴\n",
    "- LoRA - Adapter\n",
    "    - 기존에 모델을 구성하고 있던 계층과는 별개의 파라미터를 사용하는 개념\n",
    "    - forward 연산은 pretrained weights와 adapter를 따로 수행하고, 각 결과를 합쳐서 다음 레이어에 보냄\n",
    "    - backward 연산은 pretrained weights가 필요하지 않고, adapter는 파라미터 수가 굉장히 적어서 가능\n",
    "    - but 이렇게 하면, forward 추론 시 불리하기에, 학습이 끝난 adapter의 가중치를 pretrained weights에 더하면서 해결\n",
    "- PEFT\n",
    "    - Parameter-Efficient Fine-Tuning\n",
    "    - 적은 수의 매개변수만 학습시켜 LLM을 효율적으로 파인튜닝하는 기술들의 집합\n",
    "- 학습 로직\n",
    "    - 기존 학습/추론 로직\n",
    "        - 데이터 로드 → 데이터셋 클래스 만들기 → 모델, 학습 args 불러오기 → Trainer로 ‘데이터, 모델, args’ 감싸기 → Trainer.train()\n",
    "    - LoRA 추가 시 학습/추론 로직\n",
    "        - 데이터 로드 → 데이터셋 클래스 만들기 → 모델, 학습 args 불러오기 → **PEFT(LoRA)** config 설정하기 → Trainer로 **‘데이터, 모델, args, PEFT config’** 감싸기 → Trainer.train()\n",
    "- LoRA 설정\n",
    "    \n",
    "    ```python\n",
    "    from peft import LoraConfig # LoraConfig 클래스를 가져옵니다.\n",
    "    \n",
    "    # LoraConfig 객체는 LoRA 파인튜닝에 필요한 설정을 정의합니다.\n",
    "    peft_config = LoraConfig(\n",
    "        # r: LoRA의 랭크(rank)를 의미합니다.\n",
    "        # r 값이 작을수록 학습할 매개변수가 적어 메모리 사용량이 줄지만,\n",
    "        # 모델 성능이 낮아질 수 있습니다.\n",
    "        # r 값이 클수록 성능은 좋아지지만, 메모리 사용량과 학습 시간이 늘어납니다.\n",
    "        r=args.lora_r, \n",
    "    \n",
    "        # lora_alpha: LoRA 스케일링 계수입니다.\n",
    "        # LoRA 레이어의 출력을 조정하는 역할로, 일반적으로 r 값에 비례하여 설정합니다 (예: 2*r).\n",
    "        # 값이 클수록 LoRA의 영향력이 커집니다.\n",
    "        **lora_alpha**=args.lora_alpha,\n",
    "    \n",
    "        # lora_dropout: LoRA 레이어에 적용되는 드롭아웃 비율입니다.\n",
    "        # 과적합(overfitting)을 방지하기 위해 사용됩니다.\n",
    "        lora_dropout=args.lora_dropout,\n",
    "    \n",
    "        # bias: LoRA를 적용할 레이어의 편향(bias)을 학습할지 여부를 설정합니다.\n",
    "        # 'none' (기본값)은 학습하지 않고, 'lora_only'는 LoRA 레이어의 편향만,\n",
    "        # 'all'은 모든 편향을 학습합니다.\n",
    "        bias=args.lora_bias, \n",
    "    \n",
    "        # task_type: 파인튜닝할 작업의 유형을 지정합니다.\n",
    "        # 예: \"CAUSAL_LM\" (텍스트 생성), \"SEQ_CLS\" (텍스트 분류) 등.\n",
    "        # 올바른 모델 아키텍처를 선택하는 데 사용됩니다.\n",
    "        task_type=args.task_type,\n",
    "    \n",
    "        # target_modules: LoRA를 적용할 모델의 특정 모듈(레이어)을 지정합니다.\n",
    "        # 일반적으로 Transformer 모델의 어텐션(attention) 레이어인 'q_proj', 'k_proj', 'v_proj' 등을 지정합니다.\n",
    "        **target_modules**=args.target_modules \n",
    "    )\n",
    "    \n",
    "    # Trainer 객체를 생성하여 모델 학습을 준비합니다.\n",
    "    trainer = MyTrainer(\n",
    "        model=model, # 학습할 모델\n",
    "        args=training_args, # 학습에 필요한 인자들 (학습률, 에포크 수 등)\n",
    "        train_dataset=train_dataset, # 학습 데이터셋\n",
    "        eval_dataset=valid_dataset, # 검증 데이터셋\n",
    "        # peft_config: PEFT 설정을 Trainer에 전달합니다.\n",
    "        # args.peft가 True인 경우에만 LoRA 설정을 적용합니다.\n",
    "        peft_config=peft_config if args.peft else None, \n",
    "    )\n",
    "    ```\n",
    "    \n",
    "- LoRA - target_modules\n",
    "    - 각 속성에 들어갈 수 있는 속성들\n",
    "    - Attention: q_proj, k_proj, v_proj, o_proj\n",
    "    - MLP: gate_proj, up_proj, down_proj\n",
    "- 대화형 데이터를 학습에 적합한 형식으로 변환하는 과정\n",
    "    \n",
    "    ```jsx\n",
    "    def formatting_prompts_func(examples):\n",
    "       convos = examples[\"conversations\"]\n",
    "       texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False).removeprefix('<bos>') for convo in convos]\n",
    "       return { \"text\" : texts, }\n",
    "    \n",
    "    dataset = dataset.map(formatting_prompts_func, batched = True)\n",
    "    ```\n",
    "    \n",
    "    - tokenize=False\n",
    "        - 대화를 토큰 ID로 변환하지 않고, 모델이 이해할 수 있는 문자열 형식으로만 변환\n",
    "    - add_generation_prompt=False, 모델이 응답을 생성할 준비가 되었음을 나타내는 <|assistant|>와 같은 추가 프롬프트 토큰을 제거\n",
    "    - 주의할 점\n",
    "        - `assistant`는 정답이기 때문에 학습에서만 입력으로 넣어주고 추론에서는 넣으면 안됨\n",
    "        - `add_generation_prompt=False`는 `assistant`가 들어갔기 때문에 `False`로 설정\n",
    "            - 추론용이라면 `True`로 설정\n",
    "- SFT(Supervised Fine-Tuning)\n",
    "    - 특정 작업을 수행하도록 미리 학습된 대규모 언어 모델(LLM)을 학습시키는 방법\n",
    "    - 속성\n",
    "        - 전체 학습을 원한다면 num_train_epochs=1, max_steps=None\n",
    "        - 속성 코드\n",
    "            \n",
    "            ```python\n",
    "            trainer = SFTTrainer(\n",
    "                model = model,\n",
    "                tokenizer = tokenizer,\n",
    "                train_dataset = dataset,\n",
    "                args = SFTConfig(\n",
    "            \t\t    # 학습에 사용할 텍스트가 담긴 열 \n",
    "                    dataset_text_field=\"text\",\n",
    "                    \n",
    "                    # 하나의 GPT당 훈련 배치 크기 \n",
    "                    # 배치 크기가 크면 학습이 안정적일 수 있지만, 많은 메모리 필요\n",
    "                    per_device_train_batch_size = 8,\n",
    "                    \n",
    "                    # 기울기를 축적하는 단계 수\n",
    "                    # 기울기를 축적하면 배치 크기가 더 큰 것처럼 학습 가능\n",
    "                    # GPU 메모리가 부족해 배치 크기를 키우지 못할 때 유용 \n",
    "                    # ex) 4로 설정하면, 8개짜리 배치를 4번 처리한 기울기를 누적했다가\n",
    "                    # 한번에 없데이트 \n",
    "                    gradient_accumulation_steps = 1,\n",
    "                    \n",
    "                    # 학습률을 점진적으로 증가시키는 단계 수 \n",
    "                    warmup_steps = 5,\n",
    "                    \n",
    "                    # 전체 학습에 사용할 최대 업데이트 단계 수\n",
    "                    # 클수록 더 오래 학습 진행 \n",
    "                    max_steps = 100,\n",
    "                    \n",
    "                    # 학습의 속도를 결정하는 핵심 파라미터\n",
    "                    # 크면 최적점을 지나치고, 작으면 학습 속도가 느려짐\n",
    "                    learning_rate = 5e-5,\n",
    "                    \n",
    "            \t\t\t\t# 몇 단계마다 로그를 기록할지 결정\n",
    "                    logging_steps = 1,\n",
    "                    \n",
    "                    # 최적화 도구를 지정 \n",
    "                    optim = \"adamw_8bit\",\n",
    "                    \n",
    "                    # 가중치 감쇠(L2 정규화) 값 - 과적합 방지\n",
    "                    weight_decay = 0.01,\n",
    "                    \n",
    "                    # 학습률 스케쥴러의 종류를 지정 \n",
    "                    # linear는 학습 초기에 학습률을 서서히 높였다가 점진적으로 낮추는 방식\n",
    "                    lr_scheduler_type = \"linear\",\n",
    "                    \n",
    "                    # 모델 체크포인트와 로그 파일이 저장될 디렉토리\n",
    "                    output_dir = \"outputs\",\n",
    "                    \n",
    "                    # 학습 진행 상황을 보고할 플랫폼 (ex: wandb)\n",
    "                    report_to = \"none\",\n",
    "                ),\n",
    "            )\n",
    "            ```\n",
    "            \n",
    "- Unsloth - train_on_responses_only\n",
    "    - User Input에 대한 loss는 무시하고 오직 assistant(정답 라벨) output만 학습\n",
    "    - 즉, 사용자 질문이 아닌 응답에서만 학습하라는 의미\n",
    "    - 코드\n",
    "    \n",
    "    ```python\n",
    "    trainer = train_on_responses_only(\n",
    "        trainer,\n",
    "        instruction_part = instruction_part,\n",
    "        response_part = response_part,\n",
    "    )\n",
    "    ```\n",
    "    \n",
    "- transformers 라이브러리를 사용하여 LLM이 텍스트를 생성하는 과정\n",
    "    \n",
    "    ```python\n",
    "    from transformers import TextStreamer\n",
    "    _ = model.generate(\n",
    "    \t\t# 입력 텍스트를 토큰화 \n",
    "        **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "        max_new_tokens = 125,\n",
    "        # temperature: 1에 가까울수록 무작위적이고 창의적\n",
    "        # top_p: 핵심 샘플링을 위한 파라미터, 높으면 예상 가능한 답변\n",
    "        # top_k : Top-k 샘플링을 위한 파라미터, 고려할 후보 개수 \n",
    "        temperature = 1, top_p = 0.95, top_k = 64,\n",
    "        # 모델의 답변을 실시간으로 스트리밍하는 기능을 활성화 \n",
    "        # skip_prompt: 모델이 생성하는 새로운 텍스트만 화면에 보여줌 \n",
    "        streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    "    )\n",
    "    ```\n",
    "    \n",
    "- NLP에서 중요하게 체크해야 할 EDA 항목\n",
    "    1. sequence length\n",
    "    2. langauge\n",
    "    3. input data domain\n",
    "- pad_token\n",
    "    - 데이터를 효율적으로 처리하기 위해서 “가장 긴 문자의 길이에 맞춰 나머지 짧은 문장의 뒤에 채워 넣는 역할”\n",
    "- eos_token\n",
    "    - 문장이 어디서 끝나는지 보여주는 토큰\n",
    "- 양자화(Quantization)\n",
    "    - 모델의 매개변수를 더 낮은 정밀도로 표현하여 모델의 크기와 연산량을 줄이는 기술\n",
    "    - 연산/메모리 부하를 줄이는 가장 직관적인 방법\n",
    "- PTQ(Post-Traning Quantization)\n",
    "    - 모델 학습이 완료된 후, 모델의 가중치와 화설호아 함수 값을 낮은 정밀도로 변환\n",
    "    - 재학습 과정이 필요 없어서 매우 간단하지만 정확도 손실이 발생할 수 있음\n",
    "- QAT(Quantization-Aware Training)\n",
    "    - **모델 학습 과정**에 양자화를 추가시켜 모델이 낮은 정밀도에 적응하도록 훈련하는 방식\n",
    "    - 정확도 손실이 적지만, 복잡하고 학습데이터가 필요함\n",
    "- weight-only quantization vs weight-activation quantization\n",
    "    - weight-only quantization(가중치 전용 양자화)\n",
    "        - 가중치만 양자화하는 방식\n",
    "        - 모델 크기의 대부분을 차지하는 가중치를 압축하기 때문에 공간을 크게 아낄 수 있음\n",
    "        - 활성화 값은 여전히 높은 정밀로 계싼되기 때문에 추론 속도나 사용량을 개선하진 못함\n",
    "    - weight-activation quantization(가중치 활성화 양자화)\n",
    "        - 가중치와 활성화 값 모두를 낮은 정밀도로 양자화하는 방법\n",
    "        - 모델 크기를 최대로 줄이고, 효율을 올릴 수 있음\n",
    "        - 복잡하고, 모델 정확도 손실이 더 클 수 있음\n",
    "- Symmetric vs Asymmetric\n",
    "    - Symmetric(대칭)\n",
    "        - 원점을 중심으로 양자화 범위를 설정, 최대/최소 절대값이 같도록 범위를 설정\n",
    "        - 간단하지만, 데이터 분포가 비대칭적일 경우, 사용되지 않는 양자화 범위가 생겨서 정확도 손실이 생길 수 있음\n",
    "    - Asymmetric(비대칭)\n",
    "        - 실제 데이터의 최솟값과 최댓값에 맞춰 양자화 범위를 설정\n",
    "        - 정확도 손실이 적지만, zero-point(원점)을 따로 관리해야 해서 구현이 까다로움\n",
    "- Mixed-precision quantization\n",
    "    - 모델의 각기 다른 부분에서 서로 다른 정밀도를 적용하는 양자화 방식\n",
    "    - 효율적이고, 높은 유연성이 있음\n",
    "    - 복잡하고, 하드웨어 제약이 있을 수 있음\n",
    "- 양자화 - Pruning\n",
    "    - 가지치기\n",
    "    - 모델의 가중치 중 중요도가 낮은 연결을 제거하여 모델을 작게 만드는 기술\n",
    "    - magnitude-based pruning\n",
    "        - 신경망 가중치의 절대값 크기를 기준으로 중요도가 낮은 가중치를 제거\n",
    "        - 가장 간단하고 일반적인 가지치기 기법\n",
    "- 양자화 - Unstructured vs Structured\n",
    "    - Unstructured(비정형)\n",
    "        - 모델의 구조와 관계없이 개별 가중치를 제거하는 방식\n",
    "        - 정확도 손실 없이 많은 가중치를 제거할 수 있음\n",
    "        - 모델의 연결이 불규칙적으로 끊어지기에, 효율적인 연산이 어려움\n",
    "    - Structured Pruning(정형)\n",
    "        - 모델의 구조(채널, 필터, 행, 열) 단위로 가중치를 제거하는 방식\n",
    "        - 효율적이지만, 모델 압축률이 낮을 수 있음\n",
    "- 가지치기 인덱싱 데이터 형식\n",
    "    - 불필요한 0의 가중치들을 제외하고, 유효한 값들만 저장하는 방식\n",
    "    - COO(Coordinate)\n",
    "        - 0이 아닌 각 원소를 (행 좌표, 열 좌표)의 형태로 저장\n",
    "        - 직관적이고, 쉽게 추가/삭제가 가능\n",
    "        - 인덱스 정보를 모두 저장해야 해서 메모리 사용량이 큼\n",
    "    - CSR(Compressed Sparse Row) | CSC(Compressed Sparse Column)\n",
    "        - 행을 기준으로 압축\n",
    "        - value: 0이 아닌 값들을 순서대로 저장\n",
    "        - column_indices: 각 값의 열 인덱스를 저장\n",
    "        - row_pointers: 각 행의 시작 위치를 values 배열의 인덱스로 저장\n",
    "        - 행 단위로 접근하기 쉽고, 벡터 곱셈 연산에 효율적\n",
    "        - 특정 행의 모든 값을 읽거나 행을 삽입/삭제하는 것이 복잡함\n",
    "- 지식 증류 (Knowledge Distillation)\n",
    "    - **크고 똑똑한 교사 모델**의 풍부한 학습 노하우를 **작고 빠른 학생 모델**에게 전수하여, 성능은 유지하면서도 모델의 크기와 연산량을 줄이는 기술\n",
    "- PEFT\n",
    "    - Parameter-Efficient Fine-Tuning\n",
    "    - 적은 수의 매개변수만 학습시켜 LLM을 효율적으로 파인튜닝하는 기술들의 집합\n",
    "    - LoRA\n",
    "- LoRA\n",
    "    - Low-Rank Adaptation\n",
    "    - LLM을 효율적으로 파인튜닝하는 기술\n",
    "    - 적은 수의 추가적인 매개변수만 학습시켜 모델의 성능을 향상시킴\n",
    "    - 기존 가중치 고정 → 새로운 작은 행렬 추가 → 미세 조정 → 추론\n",
    "- LoRA - Adapter\n",
    "    - 기존에 모델을 구성하고 있던 계층과는 별개의 파라미터를 사용하는 개념\n",
    "    - forward 연산은 pretrained weights와 adapter를 따로 수행하고, 각 결과를 합쳐서 다음 레이어에 보냄\n",
    "    - backward 연산은 pretrained weights가 필요하지 않고, adapter는 파라미터 수가 굉장히 적어서 가능\n",
    "    - but 이렇게 하면, forward 추론 시 분리하기에, 학습이 끝난 adapter의 가중치를 pretrained weights에 더하면서 해결\n",
    "- QLoRA\n",
    "    - 경량화 + LoRA\n",
    "    - 원본 모델을 강하게 양자화 → 범용 성능의 하락\n",
    "    - LoRA의 작은 가중치 행렬을 학습\n",
    "    - 획기적인 메모리 절감, 높은 성능, 비용 횽류성, 접근성 향상"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
