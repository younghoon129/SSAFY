이 단원은 **'CNN의 핵심 구성요소(합성곱/풀링)의 역할'**과 **'계산 공식'**, 그리고 **'주요 아키텍처(VGG, ResNet, ViT)의 핵심 아이디어'**를 묻는 문제가 중요합니다. 특히 헷갈리셨던 계산 문제와 개념 비교(CNN vs ViT)에 중점을 두었습니다.

---

## ✍️ 단답형 문제 (10문제)

**문제 1.** 이미지를 1차원 벡터로 펼쳐서 처리하기 때문에 '지역 정보'를 잃어버리는 가장 기본적인 신경망 모델은 무엇인가?

**문제 2.** CNN에서 '필터(커널)'를 이미지에 훑으면서 '특징을 추출'하는 연산은 무엇인가?

**문제 3.** 합성곱 연산의 결과물로, 원본 이미지에서 특정 '특징'이 추출된 2D 데이터를 무엇이라고 하는가?

**문제 4.** 합성곱을 거친 특징 맵의 '크기를 줄여(Downsampling)' 연산 효율을 높이고 '과적합'을 방지하는 과정은 무엇인가?

**문제 5.** CNN의 마지막 단에서, 추출된 모든 특징(1D로 펼쳐짐)을 '종합'하여 '최종 분류'를 수행하는 계층은 무엇인가?

**문제 6.** CNN이 층이 깊어질수록 '더 넓은 맥락'을 이해할 수 있게 되는 것과 관련된 용어로, 한 번에 볼 수 있는 '영역의 크기'를 무엇이라고 하는가?

**문제 7.** 합성곱 필터가 이동하는 '간격(보폭)'을 조절하여 차원을 축소하는 기술은 무엇인가?

**문제 8.** '$3 \times 3$'의 '작은 필터'를 '깊게' 쌓는 것의 효율성을 증명한 CNN 모델은 무엇인가?

**문제 9.** '잔차 연결(Residual Connection)'을 도입하여 층이 매우 깊어져도 '과소적합(Degradation)' 문제를 해결한 CNN 모델은 무엇인가?

**문제 10.** NLP의 '트랜스포머' 구조를 이미지에 적용하여, '전역 문맥'을 한 번에 고려하는 Vision 모델은 무엇인가?

---

## 📜 서술형 문제 (5문제)

**문제 11. (계산 문제)**
입력 해상도가 **$28 \times 28$**인 이미지에 다음 연산을 순서대로 적용할 때, **(1)~(3)의 출력 해상도**를 각각 계산하시오.
* (1) $5 \times 5$ 필터, **패딩 2**, 스트라이드 1 적용
* (2) (1)의 결과에 $2 \times 2$ **풀링**(스트라이드 2) 적용
* (3) (2)의 결과에 $3 \times 3$ 필터, **패딩 0**, **스트라이드 2** 적용

**(공식: $W' = (W - K + 2P) / S + 1$)**

**문제 12. (계산 문제)**
어떤 합성곱 계층의 정보가 다음과 같을 때, **(1) 총 파라미터(상수) 개수**와 **(2) FLOPS(연산량)**를 계산하는 '식'을 각각 쓰시오.
* 입력 채널: 64
* 필터 개수: 128
* 커널 사이즈: $3 \times 3$
* 출력 해상도: $14 \times 14$

**(공식 참고: 파라미터 = 가중치+편향, FLOPS = 출력량 * (연산))**

**문제 13.** '합성곱(Convolution)' 연산과 '풀링(Pooling)' 연산의 **(1) 주된 목적**과 **(2) 학습 가능한 파라미터(가중치) 유무**를 비교 설명하시오.

**문제 14.** 'CNN'과 'ViT(Vision Transformer)'가 이미지를 처리하는 방식을 **(1) '지역 정보' vs '전역 문맥'** 관점, **(2) '데이터 효율성(필요한 데이터 양)'** 관점에서 비교 설명하시오.

**문제 15.** '전이 학습(Transfer Learning)'과 '증류 학습(Distillation)'의 '목적'이 어떻게 다른지 설명하시오.

---

### 📝 단답형 / 서술형 예시 답안

> **단답형 정답**
> 1.  **FCN (Fully-Connected Layer)** (또는 MLP)
> 2.  **합성곱 (Convolution)**
> 3.  **특징 맵 (Feature Map)** (Q4 오답 관련)
> 4.  **풀링 (Pooling)** (Q7 오답 관련)
> 5.  **Fully Connected Layer (완전 연결 계층)** (Q10 오답 관련)
> 6.  **수용 영역 (Receptive Field)**
> 7.  **스트라이드 (Stride)**
> 8.  **VGGNet**
> 9.  **ResNet** (Q20 오답 관련)
> 10. **ViT (Vision Transformer)** (Q23 오답 관련)
>
> ---
>
> **서술형 정답 (예시)**
> 11. **(Q15, Q16 오답 관련)**
> * (1) $W' = (28 - 5 + 2*2) / 1 + 1 = (28 - 5 + 4) / 1 + 1 = 27 + 1 = 28$. **답: $28 \times 28$**
> * (2) $2 \times 2$ 풀링 (스트라이드 2)은 해상도를 절반으로 줄입니다. **답: $14 \times 14$**
> * (3) $W' = (14 - 3 + 2*0) / 2 + 1 = 11 / 2 + 1 = 5.5 + 1 = 6.5$ (보통 내림하여 6). **답: $6 \times 6$** (또는 $7 \times 7$ - 구현에 따라 다름)
>
> 12. **(Q17, Q34, Q35 오답 관련)**
> * **(1) 파라미터 개수**: (필터 개수 $\times$ 입력 채널 $\times$ 커널^2) + (편향 개수)
>    = **(128 $\times$ 64 $\times$ 3 $\times$ 3) + 128**
> * **(2) FLOPS**: (출력량) $\times$ (1픽셀당 연산) = (출력 채널 $\times$ 출력 H $\times$ 출력 W) $\times$ (입력 채널 $\times$ 커널^2)
>    = **(128 $\times$ 14 $\times$ 14) $\times$ (64 $\times$ 3 $\times$ 3)**
>
> 13.
> * **(1) 목적**: '합성곱'은 필터(가중치)를 학습하여 이미지의 '특징을 추출'하는 것이 목적입니다. '풀링'은 특징 맵의 '크기를 줄여(Downsampling)' '계산 효율성'을 높이고 '과적합을 방지'하는 것이 목적입니다. (Q7 오답 관련)
> * **(2) 파라미터 유무**: '합성곱'의 '필터'는 학습을 통해 업데이트되는 '파라미터(가중치)'입니다. '풀링'(예: Max Pooling)은 '최댓값'이라는 '고정된 규칙'으로 작동하므로 '학습할 파라미터가 없습니다.'
>
> 14.
> * **(1) 지역/전역**: 'CNN'은 작은 '필터(커널)'로 '지역(Local)' 정보를 먼저 본 뒤, 층을 깊게 쌓아 점차 '전역(Global)' 정보를 봅니다. 'ViT'는 '셀프 어텐션'을 통해 '모든 패치(이미지 조각)' 간의 관계를 '한 번에' 고려하므로 '전역 문맥' 파악에 강합니다.
> * **(2) 데이터 효율성**: 'CNN'은 '지역성(가까운 픽셀이 관련 높음)'이라는 강력한 사전 지식(편향)이 있어 '적은 데이터'로도 효율적인 학습이 가능합니다. 'ViT'는 이런 편향이 없어 '대규모 데이터'가 있어야만 CNN의 성능을 능가할 수 있습니다. (Q37 오답 관련)
>
> 15.
> * **전이 학습**: (A 문제 $\rightarrow$ B 문제) '이미지넷'(A 문제)으로 학습된 '모델'을, '의료 영상'(B 문제)처럼 '새롭고 데이터가 적은' 문제를 풀 때 '재사용'하는 것이 목적입니다.
> * **증류 학습**: (Teacher $\rightarrow$ Student) '크고 복잡한' 모델(Teacher)의 '지식(Softmax 확률)'을, '작고 경량화된' 모델(Student)에게 '전달(학습)'시켜, '성능은 비슷하지만 가벼운' 모델을 만드는 것이 목적입니다. (Q28 오답 관련)

---

이 단원은 **계산 문제(11, 12번)**와 **모델 비교(13, 14, 15번)**가 핵심입니다.