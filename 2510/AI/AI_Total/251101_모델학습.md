# ✍️ 단답형 문제 (7문제)
문제 1. 모델이 훈련 데이터에만 너무 익숙해져서 잡음(노이즈)까지 외워버린 결과, 테스트 데이터에서는 낮은 성능을 보이는 현상을 무엇이라고 하는가?

문제 2. 모델이 너무 단순해서 훈련 데이터의 핵심 패턴조차 학습하지 못해, 훈련 데이터와 테스트 데이터 모두에서 낮은 성능을 보이는 현상을 무엇이라고 하는가?

문제 3. 데이터 분리(train_test_split) 시, 원본 데이터의 클래스 비율(Y)을 훈련/테스트 데이터에도 동일하게 유지시켜주는 옵션은 무엇인가? (힌트: _______=y)

문제 4. 데이터의 평균을 0, 표준편차를 1로 변환하는 스케일링 기법은 무엇인가?

문제 5. 데이터의 값을 0과 1 사이로 축소하며, 최소/최댓값을 직접 사용하기 때문에 이상치에 민감한 스케일링 기법은 무엇인가?

문제 6. (       )은/는 훈련 과정에서 '테스트 데이터'의 정보(예: 평균, 표준편차)가 '훈련 데이터'에 유입되어 모델의 성능이 비정상적으로 높게 평가되는 현상을 말한다.

문제 7. '표준화'와 '정규화' 중, 이상치(Outlier)에 '덜 민감한(Robust)' 스케일링 기법은 무엇인가?

# 📜 서술형 문제 (5문제)
문제 8. 데이터를 '훈련 데이터'와 '테스트 데이터'로 분리하는 이유와, '과적합'의 개념을 연관 지어 설명하시오.

문제 9. '과적합(Overfitting)'과 '과소적합(Underfitting)'의 특징을 (1) 모델의 복잡도 관점, (2) 훈련/테스트 데이터 성능 관점에서 각각 비교 설명하시오.

문제 10. '표준화(Standardization)'와 '정규화(Normalization)'를 (1) 변환 공식(또는 목표 범위), (2) 이상치 민감도 관점에서 비교 설명하시오.

문제 11. stratify=y 옵션이 '클래스가 불균형한' 데이터(예: 99% 정상, 1% 사기)를 분리할 때 반드시 필요한 이유를 최악의 시나리오와 함께 설명하시오.

문제 12. (⭐️ 매우 중요) 데이터 스케일링(예: 표준화)을 수행할 때, (1) 왜 스케일러(Scaler)를 '훈련 데이터'로만 fit해야 하는지, (2) 그리고 (2) 왜 '테스트 데이터'에는 fit을 하지 않고 transform만 적용해야 하는지 '데이터 누수(Data Leakage)'의 개념을 사용하여 설명하시오.

# 📝 단답형 / 서술형 예시 답안
단답형 정답

과적합 (Overfitting)

과소적합 (Underfitting)

stratify

표준화 (Standardization)

정규화 (Normalization)

데이터 누수 (Data Leakage)

표준화 (Standardization)

서술형 정답 (예시) 8. 데이터를 분리하는 이유는 모델의 '일반화 성능'을 '공정하게 평가'하기 위함입니다. 만약 데이터를 분리하지 않고 훈련 데이터로만 평가하면, 모델이 훈련 데이터의 잡음까지 모두 외워버린 '과적합' 상태임에도 불구하고 성능이 100%로 잘못 측정될 수 있습니다. 따라서 '처음 보는 데이터(테스트 데이터)'를 통해 과적합 여부를 확인하고 모델의 진짜 실력을 평가해야 합니다.

과적합: (1) 모델이 '너무 복잡하여' 훈련 데이터의 잡음까지 암기한 상태입니다. (2) '훈련 데이터' 성능은 매우 높지만(예: 99%), '테스트 데이터' 성능은 낮습니다(예: 70%).

과소적합: (1) 모델이 '너무 단순하여' 훈련 데이터의 핵심 패턴조차 학습하지 못한 상태입니다. (2) '훈련 데이터' 성능도 낮고(예: 60%), '테스트 데이터' 성능도 낮습니다(예: 61%).

표준화: (1) 데이터의 '평균을 0, 표준편차를 1'로 변환합니다. (2) 평균/표준편차를 사용하므로 이상치에 영향을 받긴 하지만, 정규화보다는 '덜 민감(Robust)'합니다.

정규화: (1) 데이터의 '최소값을 0, 최댓값을 1'로 변환합니다. (2) 공식에 최소/최댓값을 직접 사용하므로, 이상치 1개에 전체 스케일이 찌그러지는 '매우 민감한' 방식입니다.

'사기(1%)' 데이터가 매우 적기 때문에, stratify 없이 무작위 분리 시 최악의 경우 '테스트 데이터'에 '사기' 샘플이 0개 할당될 수 있습니다. 이 경우, 모델이 모든 것을 '정상'으로만 예측해도 테스트 정확도가 100%로 나오는, 사기를 전혀 탐지하지 못하는 '가짜 모델'이 만들어지게 됩니다. stratify=y는 이 '사기' 클래스를 훈련/테스트에 1% 비율로 강제 배분하여 이러한 상황을 막습니다.

(1) 모델은 '훈련 데이터'만을 보고 학습되어야 합니다. 스케일링의 '기준'(평균/std/min/max) 역시 훈련 데이터의 일부로 간주되므로, **오직 '훈련 데이터'의 정보로만 fit(기준 학습)**을 해야 합니다.

(2) 만약 '테스트 데이터'로 fit을 하거나(또는 fit_transform), '전체 데이터'로 fit을 한다면, 이는 '미래(테스트)'의 정보(평균/std 등)가 '과거(훈련)'의 기준 설정에 영향을 미치는 **'데이터 누수(Data Leakage)'**입니다. 이는 공정한 평가를 불가능하게 만듭니다. 따라서 테스트 데이터는 '과거(훈련)'에 학습된 '동일한 기준'으로 '변환(transform)'만 되어야 합니다.