# LLM
- NLP
    - 텍스트 분류
        - 주어진 텍스트 문서를 여러 범주 중 하나로 분류
    - 개체명 인식
        - 텍스트에서 이름, 장소, 날짜 등을 식별하고 추출
    - 감정 분석
        - 텍스트내에서 긍정적, 부정적, 중립적인 감정을 분류 및 scoring
    - 텍스트 요약
        - 긴 텍스트 문서를 간결하게 요약 및 중요한 정보를 추출
    - 기계 번역
        - 다른 언어로 작성된 텍스트를 목표하는 언어로 번역
    - 질문 응답
        - 사용자가 질문에 대한 답변을 추출 및 생성
    - 대화형 인터페이스
        - 챗봇 등을 통해 User와 대화 인터페이스 구축
    - 문서 유사성 측정
        - 두 개 이상의 문서 간의 유사성을 측정하는 기술
    - 자연어 생성
        - 모델이 텍스트를 자동으로 생성하는 기술

## 기존 Sequence를 다루던 모델
- RNN: 순환 구조로 시퀀스 데이터 처리
- LSTM: 장기 의존성 해결, 세 가지 게이트 사용
- GRU: LSTM의 간단한 버전, 계산 효율성 증가

## RNN 모델의 문제점
- 기울기 소실 / 폭발
    - 곱연산 계속 되다 보니 
    - 0~1: 0에 수렴
    - 1 이상: 폭발
- 장기 의존성 문제
- 해결방법
    - Attention RNN
    - Attention(QKAV)
        - Self-Attention, Query와 Key, Value의 시작 값이 동일
        - 문장에서의 단어들의 연관성 파악에 용이
    - Multi-head
        - 타입에 집중하는 어텐션
        - 문장
        - 명사
        - 관계
        - 강조

## 기존 ML과 생성형의 차이
- Autoencoding Model
    - 일반적으로 인코더만으로 구성
    - 입력 데이터의 전체 구조 학습
    - 입력데이터의 재구성하는 오류를 최소화 하는 방향으로 학습
    - 문서분류, 문장 이해, 문서 임베딩 등
- Autoregressive Model(Decoder Only)
    - 일반적으로 디코더만으로 구성
    - 순차적 데이터를 기반으로 다음 예측
    - 주어진 시퀀스의 다음 값을 예측하는 오류를 최소화 하는 방향으로 훈련
    - 텍스트 생성, 대화형 AI 등

## 한계점
- AI 활용 시 주요 한계와 위험 요소
    - 윤리적 문제
    - 편향
    - 할루시네이션
    - 최신 정보 반영 한계
    - 복잡한 추론, 상식 부족
    - 창의성 한계


## Tokenizer: Byet Pair Endoding의 원리
- 초기화
- 빈도계싼
- 쌍 병함
- 반복
- Transformer Decoder Layer
    - 각 토큰이 다른 모든 토큰들과의 관계 학습
        - Self-Attention Mechanism
    - 이텐션 매커니즘 후에 위치한 완전 연결 층
        - Feed-Forward Neural Network
    - 학습 안정성 및 훈련 속도 향상
        - Layer Normalization
    - Gradient 소실 문제를 완화
        - Residual Connections


## Top-k, Top-p
- 그리드 서치, 빔 서치의 단점을 보완하기 위해 Top-k, Top-p 나옴
- 그러나 Top-k, Top-p 도 단점이 있음

## Min-p Samplinf: Dynamic Truncation
- Top-k, Top-p 의 단점을 보완하기 위해 Min-p Samplinf 알고리즘이 나옴
- 하한선을 동적으로 변경할 수 있게 함

## Chain of Thought(CoT)란?
- LLM이 최종 답변에 도달하기 전에 중간 추론 단계들을 표현하도록 유도하는 기법
- 이는 인간의 추론을 반영하여 일련의 일관된 논리적 추론을 통해 체계적인 문제 해결을 촉진
- CoT는 복잡한 문제를 해결할 때 논리적 단계를 통해 작업을 보여주도록 LLM을 유도함으로써, 최종 답변의 정확도를 높이는 데 중점을 둠
- LLM에서 복잡한 문제에 대해 단순히 짧은 답변만을 요구하면 신뢰성이 떨어짐
- 특히 수학적 문제나 논리적 추론이 필요한 과제에서는 이러한 연상이 두드러짐
- 다양한 추론 작업에서 뛰어난 성능 향상을 보여줌
    - 산술 추론
    - 상식적 추론
    - 기호적 추론
- 기존의 프롬프팅 방법과 달리, CoT는 각 단계에서 모델이 추론을 평가하도록하여 오류가 발생하는 경우 대안적인 방법으로 전환할 수 있게 함
- 핵심 아이디어는 LLM에게 사고 과정을 안내하는 일련의 프롬프트를 제공하는 것
- 각 프롬프트는 '사고 노드'로 작용하며, 모델은 각 노드의 출력을 평가한 후 다음 단계로 넘어갈 수 있음
- 이를 통해 큰 언어 모델의 추론 능력을 크게 향상시킬 수 있음
    - 정확도
        - 문제를 더 작은 작업으로 분할함으로써 모델이 각 단계에 집중할 수 있어 더 정확한 결과를 도출
    - 복잡한 과제
        - 수학 문제를 해결하거나 복잡한 시나리오를 해석하는 경우, CoT를 사용하면 언어 모델이 효율적으로 처리 가능